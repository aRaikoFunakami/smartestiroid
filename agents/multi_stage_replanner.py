"""
Multi-stage replanner for SmartestiRoid test framework.

This module provides a 3-stage replanning process for mini models.
"""

from typing import List, Dict, Any
from colorama import Fore
from langchain_core.messages import HumanMessage
import allure

from models import Plan, Response, DecisionResult
from config import RESULT_PASS, RESULT_FAIL


class MultiStageReplanner:
    """3æ®µéšã«åˆ†ã‘ã¦replanã‚’å®Ÿè¡Œã™ã‚‹ã‚¯ãƒ©ã‚¹ï¼ˆminiãƒ¢ãƒ‡ãƒ«ç”¨ï¼‰"""
    
    def __init__(self, llm, knowhow: str, token_callback=None):
        self.llm = llm
        self.knowhow = knowhow
        self.model_name = llm.model_name if hasattr(llm, 'model_name') else "unknown"
        self.token_callback = token_callback  # track_query()ç”¨ã«ä¿æŒ
    
    async def analyze_state(
        self,
        goal: str,
        original_plan: list,
        past_steps: list,
        locator: str,
        previous_image_url: str = "",
        current_image_url: str = ""
    ) -> str:
        """ã‚¹ãƒ†ãƒ¼ã‚¸1: ç”»åƒï¼ˆå‰å›/ç¾åœ¨ï¼‰ã¨ãƒ­ã‚±ãƒ¼ã‚¿ãƒ¼ã‹ã‚‰ç¾çŠ¶ã‚’æŠŠæ¡

        ç”»åƒãŒã‚ã‚‹å ´åˆã¯LLMã¸ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«ã§æ¸¡ã—ã€å·®åˆ†è¨€åŠã‚’ä¿ƒã™ã€‚
        """
        prompt_text = f"""
ã‚ãªãŸã¯ç”»é¢çŠ¶æ…‹ã‚’åˆ†æã™ã‚‹ã‚¨ã‚­ã‚¹ãƒ‘ãƒ¼ãƒˆã§ã™ã€‚

ç›®æ¨™:
{goal}

å…ƒã®è¨ˆç”»ã‚¹ãƒ†ãƒƒãƒ—æ•°: {len(original_plan)}
å®Œäº†æ¸ˆã¿ã‚¹ãƒ†ãƒƒãƒ—æ•°: {len(past_steps)}
æœ€å¾Œã®å®Œäº†ã‚¹ãƒ†ãƒƒãƒ—: {past_steps[-1][0] if past_steps else "(ãªã—)"}


æŒ‡ç¤º:
ç›®æ¨™ãŒé”æˆã•ã‚Œã¦ã„ã‚‹ã‹å¦ã‹ã‚’ã€ç”»é¢ã®ãƒ­ã‚±ãƒ¼ã‚¿æƒ…å ±ã¨ã€å‰å›ã¨ç¾åœ¨ã®ç”»é¢ã‚¹ã‚¯ãƒªãƒ¼ãƒ³ã‚·ãƒ§ãƒƒãƒˆã‚’åŸºã«åˆ¤æ–­ã—ã¦ãã ã•ã„ã€‚
ç”»åƒå·®åˆ† / ãƒ†ã‚¹ãƒˆé€²æ— / å•é¡Œå…†å€™ / ä¸»è¦è¦ç´  ã‚’åˆ†æã—ãŸçµæœã«åŠ ãˆã¦ã€ç›®æ¨™ãŒé”æˆã•ã‚Œã¦ã„ã‚‹ã‹å¦ã‹ã‚’åˆ¤æ–­ã—ãŸç†ç”±ã‚’ãƒ­ã‚±ãƒ¼ã‚¿ãƒ¼æƒ…å ±ã¨å…±ã«è©³ç´°ã«ç¤ºã—ãªã•ã„ã€‚

å³æ ¼ãƒ«ãƒ¼ãƒ«:
æ®‹ã‚Šæ¨å®šã‚¹ãƒ†ãƒƒãƒ—æ•°ãŒ1ä»¥ä¸Šã§ã‚ã‚Œã°ã€ãã‚ŒãŒçœç•¥å¯èƒ½ã«è¦‹ãˆã¦ã‚‚å¿…ãš PLAN ã‚’è¿”ã—ã¦ãã ã•ã„ã€‚Response ã‚’è¿”ã—ã¦ã‚ˆã„ã®ã¯æ®‹ã‚Šæ¨å®šã‚¹ãƒ†ãƒƒãƒ—æ•°ãŒ0 ã‹ã¤ STATE_SUMMARY ã‹ã‚‰é”æˆæ ¹æ‹ ï¼ˆè¦ç´ ç¢ºèªç­‰ï¼‰ãŒæ˜ç¢ºãªå ´åˆã®ã¿ã§ã™ã€‚
ãªãœãªã‚‰ã€çœç•¥å¯èƒ½ã«è¦‹ãˆãŸã¨ã—ã¦ã‚‚ã€ãã®ã‚¹ãƒ†ãƒƒãƒ—ã‚’åæ˜ ã™ã‚‹ã“ã¨ãŒãƒ†ã‚¹ãƒˆã®æ­£ç¢ºæ€§ã¨å®‰å…¨æ€§ã‚’é«˜ã‚ã‚‹ã‹ã‚‰ã§ã™ã€‚
ã—ãŸãŒã£ã¦ã€"çœç•¥" ã‚„ "ä¸è¦" ã¨ã„ã£ãŸèªã§æœªå®Ÿè¡Œã‚¹ãƒ†ãƒƒãƒ—ã‚’è©•ä¾¡ã—ã¦ã¯ã„ã‘ã¾ã›ã‚“ã€‚"çœç•¥å¯èƒ½"ã¨åˆ¤æ–­ã—ãŸå ´åˆã§ã‚‚ã€å¿…ãšãã®ã‚¹ãƒ†ãƒƒãƒ—ã‚’å®Ÿè¡Œã—ãªã‘ã‚Œã°ãªã‚‰ãªã„å‰æã§PLANã‚’è¿”ã—ã¦ãã ã•ã„ã€‚

å‡ºåŠ›å½¢å¼:
1. **ç”»é¢ã®å¤‰åŒ–ã¨å·®åˆ†åˆ†æ**  
å‰ã‚¹ãƒ†ãƒƒãƒ—ã‹ã‚‰ã®å¤‰æ›´ç‚¹ã‚’ã€ç‰¹ã«é‡è¦ãªUIå·®åˆ†ã«ç„¦ç‚¹ã‚’å½“ã¦ã¦è¨˜è¿°ã™ã‚‹ã“ã¨ã€‚

2. **ãƒ†ã‚¹ãƒˆé€²æ—**  
ç¾åœ¨ã®ãƒ†ã‚¹ãƒˆçŠ¶æ…‹ã‚’å®šé‡çš„ã¾ãŸã¯å®šæ€§çš„ã«è©•ä¾¡ã—ã¦ç¤ºã™ã“ã¨ã€‚

3. **å•é¡Œå…†å€™ã®æœ‰ç„¡**  
ç•°å¸¸æŒ™å‹•ãƒ»ã‚¨ãƒ©ãƒ¼ãƒ»äºˆæœŸã—ãªã„é·ç§»ã®æœ‰ç„¡ã‚’åˆ¤æ–­ã—ã€è©³ç´°ã«è¨˜è¿°ã™ã‚‹ã“ã¨ã€‚

4. **ç”»é¢ä¸»è¦è¦ç´ ã®ç¢ºèªã¨èª¬æ˜**  
ç¾åœ¨ã®ç”»é¢ãŒä½•ã‚’è¡¨ç¤ºã—ã¦ã„ã‚‹ã‹ã‚’ç†è§£ã™ã‚‹ãŸã‚ã€  
ä¸»è¦ãªUIè¦ç´ ã‚’ **ç”»åƒãƒ™ãƒ¼ã‚¹** åŠã³ **ãƒ­ã‚±ãƒ¼ã‚¿ï¼ˆä¾‹: XPath, CSS Selectorï¼‰** ã«ã‚ˆã£ã¦ç¢ºèªã—ã€  
ãã‚Œãã‚Œã®å½¹å‰²ã‚„æ„å›³ã‚’è©³ç´°ã«èª¬æ˜ã™ã‚‹ã“ã¨ã€‚

5. **ç›®æ¨™é”æˆã®å¯å¦**  
ãƒ†ã‚¹ãƒˆã®ç›®æ¨™ãŒé”æˆã•ã‚Œã¦ã„ã‚‹ã‹æ˜ç¢ºã«åˆ¤å®šã™ã‚‹ã“ã¨ã€‚

6. **ç›®æ¨™é”æˆå¯å¦ã®ç†ç”±**  
åˆ¤æ–­æ ¹æ‹ ã‚’ãƒ­ã‚±ãƒ¼ã‚¿æƒ…å ±ãŠã‚ˆã³å®Ÿéš›ã®ç”»é¢çŠ¶æ³ã«åŸºã¥ãè«–ç†çš„ã«è¨˜è¿°ã™ã‚‹ã“ã¨ã€‚

7. **ã‚¹ãƒ†ãƒƒãƒ—æ”¹å–„æ¡ˆï¼ˆä»»æ„ï¼‰**  
æ”¹å–„ã§ãã‚‹æ“ä½œã‚„æ¤œè¨¼è¦³ç‚¹ãŒã‚ã‚Œã°å…·ä½“çš„ã«ææ¡ˆã™ã‚‹ã“ã¨ã€‚

ç¾åœ¨ã®ãƒ­ã‚±ãƒ¼ã‚¿ãƒ¼æƒ…å ±:
{locator}

ç”»é¢ã‚¹ã‚¯ãƒªãƒ¼ãƒ³ã‚·ãƒ§ãƒƒãƒˆï¼ˆå‰å›ã®ç”»é¢ã¨ç¾åœ¨ã®ç”»é¢):
"""

        content_blocks: List[Dict[str, Any]] = [{"type": "text", "text": prompt_text}]
        if previous_image_url:
            content_blocks.append({"type": "image_url", "image_url": {"url": previous_image_url}})
        if current_image_url:
            content_blocks.append({"type": "image_url", "image_url": {"url": current_image_url}})

        # ç”»åƒãŒç„¡ã„å ´åˆã¯ãƒ†ã‚­ã‚¹ãƒˆã®ã¿
        if self.token_callback:
            with self.token_callback.track_query() as query:
                res = await self.llm.ainvoke([HumanMessage(content=content_blocks)])
                report = query.report()
                if report:
                    print(Fore.YELLOW + f"[analyze_state] {report}")
                    allure.attach(
                        report,
                        name="ğŸ’° Analyze State Query Token Usage",
                        attachment_type=allure.attachment_type.TEXT
                    )
        else:
            res = await self.llm.ainvoke([HumanMessage(content=content_blocks)])
        
        print(Fore.MAGENTA + f"[MultiStageReplanner.analyze_state model: {self.model_name}] State analysis completed")
        return res.content.strip()
    
    async def decide_action(self, goal: str, original_plan: list, past_steps: list, state_summary: str) -> tuple:
        """ã‚¹ãƒ†ãƒ¼ã‚¸2: Plan/Responseã©ã¡ã‚‰ã‚’è¿”ã™ã¹ãã‹åˆ¤æ–­ï¼ˆæ§‹é€ åŒ–å‡ºåŠ›ï¼‰"""
        remaining_steps = max(len(original_plan) - len(past_steps), 0)

        prompt = f"""ã‚ãªãŸã¯æ¬¡ã®ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã‚’å³å¯†ã«åˆ¤æ–­ã™ã‚‹ã‚¨ã‚­ã‚¹ãƒ‘ãƒ¼ãƒˆã§ã™ã€‚

ã€ç›®æ¨™ã€‘
{goal}

ã€çŠ¶æ…‹è¦ç´„ã€‘
{state_summary}

ã€é€²æ—ã€‘
è¨ˆç”»ã‚¹ãƒ†ãƒƒãƒ—ç·æ•°: {len(original_plan)} / å®Œäº†: {len(past_steps)} / æ®‹ã‚Š: {remaining_steps}

ã€åˆ¤æ–­åŸºæº–ï¼ˆå³æ ¼ï¼‰ã€‘
1. æ®‹ã‚Šã‚¹ãƒ†ãƒƒãƒ—ãŒï¼‘ä»¥ä¸Šå­˜åœ¨ã™ã‚‹ : decision=PLAN ï¼ˆçœç•¥å¯èƒ½ã«è¦‹ãˆã¦ã‚‚å¿…ãš PLANï¼‰
2. æ®‹ã‚Šã‚¹ãƒ†ãƒƒãƒ—ãŒå­˜åœ¨ã›ãšç›®æ¨™ãŒ100%é”æˆæ¸ˆã¿ã§è¿½åŠ è¡Œå‹•ãŒè«–ç†çš„ã«ä¸€åˆ‡ä¸è¦ : decision=RESPONSE
3. ç”»é¢/ãƒ­ã‚±ãƒ¼ã‚¿ãƒ¼ã«ä¸æ•´åˆãƒ»ã‚¨ãƒ©ãƒ¼å…†å€™ãŒã‚ã‚‹ â†’ decision=PLAN

ã€å³æ ¼ãƒ«ãƒ¼ãƒ«ã€‘
æ®‹ã‚Šæ¨å®šã‚¹ãƒ†ãƒƒãƒ—æ•°ãŒ1ä»¥ä¸Šã§ã‚ã‚Œã°ã€ãã‚ŒãŒçœç•¥å¯èƒ½ã«è¦‹ãˆã¦ã‚‚å¿…ãš PLAN ã‚’è¿”ã—ã¦ãã ã•ã„ã€‚Response ã‚’è¿”ã—ã¦ã‚ˆã„ã®ã¯æ®‹ã‚Šæ¨å®šã‚¹ãƒ†ãƒƒãƒ—æ•°ãŒ0 ã‹ã¤ STATE_SUMMARY ã‹ã‚‰é”æˆæ ¹æ‹ ï¼ˆè¦ç´ ç¢ºèªç­‰ï¼‰ãŒæ˜ç¢ºãªå ´åˆã®ã¿ã§ã™ã€‚
ãªãœãªã‚‰ã€çœç•¥å¯èƒ½ã«è¦‹ãˆãŸã¨ã—ã¦ã‚‚ã€ãã®ã‚¹ãƒ†ãƒƒãƒ—ã‚’åæ˜ ã™ã‚‹ã“ã¨ãŒãƒ†ã‚¹ãƒˆã®æ­£ç¢ºæ€§ã¨å®‰å…¨æ€§ã‚’é«˜ã‚ã‚‹ã‹ã‚‰ã§ã™ã€‚
ã—ãŸãŒã£ã¦ã€"çœç•¥" ã‚„ "ä¸è¦" ã¨ã„ã£ãŸèªã§æœªå®Ÿè¡Œã‚¹ãƒ†ãƒƒãƒ—ã‚’è©•ä¾¡ã—ã¦ã¯ã„ã‘ã¾ã›ã‚“ã€‚"çœç•¥å¯èƒ½"ã¨åˆ¤æ–­ã—ãŸå ´åˆã§ã‚‚ã€å¿…ãšãã®ã‚¹ãƒ†ãƒƒãƒ—ã‚’å®Ÿè¡Œã—ãªã‘ã‚Œã°ãªã‚‰ãªã„å‰æã§PLANã‚’è¿”ã—ã¦ãã ã•ã„ã€‚

ã€å‡ºåŠ›ä»•æ§˜ã€‘
å³æ ¼ãªJSON
"""

        messages = [HumanMessage(content=prompt)]
        structured_llm = self.llm.with_structured_output(DecisionResult)
        try:
            if self.token_callback:
                with self.token_callback.track_query() as query:
                    result = await structured_llm.ainvoke(messages)
                    report = query.report()
                    if report:
                        print(Fore.YELLOW + f"[decide_action] {report}")
                        allure.attach(
                            report,
                            name="ğŸ’° Decide Action Query Token Usage",
                            attachment_type=allure.attachment_type.TEXT
                        )
            else:
                result = await structured_llm.ainvoke(messages)
            
            print(Fore.MAGENTA + f"[MultiStageReplanner.decide_action model: {self.model_name}] Decision: {result.decision}")
            decision_norm = result.decision.strip().upper()
            if decision_norm not in ("PLAN", "RESPONSE"):
                decision_norm = "PLAN"  # å®‰å…¨å´ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
            return decision_norm, result.reason.strip()
        except Exception as e:
            # æ§‹é€ åŒ–å‡ºåŠ›å¤±æ•—æ™‚ã¯å®‰å…¨å´ã§PLANã‚’è¿”ã™
            print(Fore.RED + f"Structured Output Error: {e}")
            allure.attach(str(e), name="âŒ decide_action: Structured Output Error", attachment_type=allure.attachment_type.TEXT)
            return "PLAN", "æ§‹é€ åŒ–å‡ºåŠ›ã‚¨ãƒ©ãƒ¼ã®ãŸã‚ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯"
    
    async def build_plan(self, goal: str, original_plan: list, past_steps: list, state_summary: str) -> Plan:
        """ã‚¹ãƒ†ãƒ¼ã‚¸3a: æ¬¡ã®Planã‚’ä½œæˆ"""
        remaining = original_plan[len(past_steps):]
        
        prompt = f"""
ã‚ãªãŸã¯å®Ÿè¡Œè¨ˆç”»ã‚’ä½œæˆã™ã‚‹ã‚¨ã‚­ã‚¹ãƒ‘ãƒ¼ãƒˆã§ã™ã€‚

ç›®æ¨™
{goal}

ç¾åœ¨ã®çŠ¶æ…‹è¦ç´„:
{state_summary}

å®Œäº†æ¸ˆã¿ã‚¹ãƒ†ãƒƒãƒ—æ•°: {len(past_steps)}

æ®‹ã‚Šã®å€™è£œã‚¹ãƒ†ãƒƒãƒ—:
{remaining}

ãƒã‚¦ãƒã‚¦:   
{self.knowhow}

ã‚¿ã‚¹ã‚¯:
ç›®æ¨™é”æˆã®ãŸã‚ã«å¿…è¦ãªæœ€é©ãªã‚¹ãƒ†ãƒƒãƒ—åˆ—ã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚ä»¥ä¸‹ã‚’å¿…ãšå®ˆã‚‹ã“ã¨ï¼š
- ã‚¹ãƒ†ãƒƒãƒ—ã‚’å®Ÿè¡Œã§ãã‚‹çŠ¶æ…‹ã§ãªã„å ´åˆã¯ã€ç¾åœ¨ã®çŠ¶æ…‹ã‚’è€ƒæ…®ã—ã¦æœ€é©ãªã‚¹ãƒ†ãƒƒãƒ—ã‚’å†æ§‹ç¯‰ã—ã¦ãã ã•ã„
- å¯èƒ½ãªã‚‰æ—¢å­˜æœªå®Œäº†ã‚¹ãƒ†ãƒƒãƒ—ã‚’å†åˆ©ç”¨ã—é‡è¤‡ã‚’é¿ã‘ã‚‹ã“ã¨
- ã‚¹ãƒ†ãƒƒãƒ—ã‚’é¸æŠã—ãŸæ ¹æ‹ ï¼ˆé€²æ—ãƒ»ç”»é¢è¦ç´ ãƒ»æ®‹ã‚Šç›®æ¨™ï¼‰ã‚’ç°¡æ½”ã«è¨€èªåŒ–ã™ã‚‹ã“ã¨
- ç¾åœ¨ã®çŠ¶æ…‹ã‚’è€ƒæ…®ã™ã‚‹ã“ã¨
- ä¸è¦ãªã‚¹ãƒ†ãƒƒãƒ—ã¯è¿½åŠ ã—ãªã„
- å„ã‚¹ãƒ†ãƒƒãƒ—ã¯å…·ä½“çš„ã§å®Ÿè¡Œå¯èƒ½ãªã“ã¨
- ç›®æ¨™ã®æ‰‹é †ã‚’è¸ã¾ãˆãŸã€ç›®æ¨™ã‚’é”æˆã™ã‚‹ãŸã‚ã®å…¨ã¦ã®ã‚¹ãƒ†ãƒƒãƒ—åˆ—ãŒãµãã¾ã‚Œã¦ã„ã‚‹ã“ã¨

å³æ ¼ãƒ«ãƒ¼ãƒ«:
- ã‚¢ã‚«ã‚¦ãƒ³ãƒˆä½œæˆã¯ç¦æ­¢
- è‡ªå‹•ãƒ­ã‚°ã‚¤ãƒ³ã¯ç¦æ­¢

å‡ºåŠ›å½¢å¼ï¼ˆJSONï¼‰:
å³å¯†ãªJSONå½¢å¼
"""
        
        messages = [HumanMessage(content=prompt)]
        structured_llm = self.llm.with_structured_output(Plan)
        
        if self.token_callback:
            with self.token_callback.track_query() as query:
                plan = await structured_llm.ainvoke(messages)
                report = query.report()
                if report:
                    print(Fore.YELLOW + f"[build_plan] {report}")
                    allure.attach(
                        report,
                        name="ğŸ’° Build Plan Query Token Usage",
                        attachment_type=allure.attachment_type.TEXT
                    )
        else:
            plan = await structured_llm.ainvoke(messages)
        
        print(Fore.MAGENTA + f"[MultiStageReplanner.build_plan model: {self.model_name}] Plan created with {len(plan.steps)} steps")
        return plan
    
    async def build_response(self, goal: str, past_steps: list, state_summary: str) -> Response:
        """ã‚¹ãƒ†ãƒ¼ã‚¸3b: å®Œäº†Responseã‚’ä½œæˆ"""
        prompt = f"""ã‚ãªãŸã¯ã‚¿ã‚¹ã‚¯å®Œäº†å ±å‘Šã‚’ä½œæˆã™ã‚‹ã‚¨ã‚­ã‚¹ãƒ‘ãƒ¼ãƒˆã§ã™ã€‚

ã€ç›®æ¨™ã€‘
{goal}

ã€ç¾åœ¨ã®çŠ¶æ…‹è¦ç´„ã€‘
{state_summary}

ã€å®Œäº†æ¸ˆã¿ã‚¹ãƒ†ãƒƒãƒ—ã€‘
{len(past_steps)}å€‹ã®ã‚¹ãƒ†ãƒƒãƒ—ã‚’å®Œäº†

ã€ã‚¿ã‚¹ã‚¯ã€‘
ã‚¿ã‚¹ã‚¯ã®å®Œäº†ã‚’å ±å‘Šã—ã¦ãã ã•ã„ã€‚ä»¥ä¸‹ã‚’å«ã‚ã‚‹ã“ã¨ï¼š
1. status: {RESULT_PASS} ã¾ãŸã¯ {RESULT_FAIL} ã®ã„ãšã‚Œã‹ã‚’è¨­å®š
2. reason: å®Œäº†ç†ç”±ã®è©³ç´°ã‚’ãƒ­ã‚±ãƒ¼ã‚¿ãƒ¼æƒ…å ±ã‚„ç”»é¢çŠ¶æ…‹ã«åŸºã¥ã„ã¦èª¬æ˜ï¼ˆ100ã€œ600æ–‡å­—ç¨‹åº¦ï¼‰
   - ç›®æ¨™ãŒé”æˆã•ã‚Œã¦ã„ã‚‹ã“ã¨ã®æ ¹æ‹ 
   - ç¢ºèªã—ãŸè¦ç´ ã®èª¬æ˜
   - å®Ÿè¡Œã—ãŸæ‰‹é †ã®å¯¾å¿œ

å‡ºåŠ›å½¢å¼:
å³æ ¼ãªJSONå½¢å¼ï¼ˆstatus ã¨ reason ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã‚’æŒã¤ï¼‰
"""
        
        messages = [HumanMessage(content=prompt)]
        structured_llm = self.llm.with_structured_output(Response)
        
        if self.token_callback:
            with self.token_callback.track_query() as query:
                resp = await structured_llm.ainvoke(messages)
                report = query.report()
                if report:
                    print(Fore.YELLOW + f"[build_response] {report}")
                    allure.attach(
                        report,
                        name="ğŸ’° Build Response Query Token Usage",
                        attachment_type=allure.attachment_type.TEXT
                    )
        else:
            resp = await structured_llm.ainvoke(messages)
        
        print(Fore.MAGENTA + f"[MultiStageReplanner.build_response model: {self.model_name}] Response created: {resp.status}")
        return resp
