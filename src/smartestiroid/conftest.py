from typing import Dict, Any, Optional
from colorama import Fore, init

from langchain_openai import ChatOpenAI
from langchain.agents import create_agent
from langgraph.graph import StateGraph, START, END
from langchain_core.messages import HumanMessage, SystemMessage
from appium.options.android import UiAutomator2Options
import base64
from PIL import Image
import io
import allure
import pytest
import json
import os
import asyncio
import time

from .appium_tools import appium_driver, appium_tools
from .appium_tools.token_counter import TiktokenCountCallback

# Import from newly created modules
from .models import (
    PlanExecute, Plan, Response, Act, DecisionResult, EvaluationResult
)
from .config import (
    OPENAI_TIMEOUT, OPENAI_MAX_RETRIES,
    MODEL_STANDARD, MODEL_MINI, MODEL_EVALUATION, MODEL_EVALUATION_MINI,
    RESULT_PASS, RESULT_SKIP, RESULT_FAIL,
    KNOWHOW_INFO
)
# ãƒ¢ãƒ‡ãƒ«å¤‰æ•°ï¼ˆplanner_modelç­‰ï¼‰ã¯ pytest_configure ã§å‹•çš„ã«å¤‰æ›´ã•ã‚Œã‚‹ãŸã‚ã€
# ç›´æ¥ã‚¤ãƒ³ãƒãƒ¼ãƒˆã›ãš cfg.planner_model ã®ã‚ˆã†ã«å‚ç…§ã™ã‚‹ï¼ˆconfig.py ã®ã‚³ãƒ¡ãƒ³ãƒˆå‚ç…§ï¼‰
from . import config as cfg
from .workflow import create_workflow_functions
from .utils.allure_logger import log_openai_error_to_allure
from .utils.device_info import write_device_info_once
from .agents import SimplePlanner


# ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ã®ãƒ«ãƒ¼ãƒˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
PACKAGE_DIR = os.path.dirname(os.path.abspath(__file__))

# ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã®capabilitiesãƒ‘ã‚¹ï¼ˆpytest_configureã§æ›´æ–°ã•ã‚Œã‚‹ï¼‰
capabilities_path = os.path.join(os.getcwd(), "capabilities.json")

init(autoreset=True)


# Pytest hooks for command-line options
def pytest_addoption(parser):
    """pytest ã‚³ãƒãƒ³ãƒ‰ãƒ©ã‚¤ãƒ³ã‚ªãƒ—ã‚·ãƒ§ãƒ³ã‚’è¿½åŠ """
    parser.addoption(
        "--knowhow",
        action="store",
        default=None,
        help="ã‚«ã‚¹ã‚¿ãƒ knowhowæƒ…å ±ã®ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ï¼ˆå…¨ãƒ†ã‚¹ãƒˆã«é©ç”¨ï¼‰"
    )
    parser.addoption(
        "--knowhow-text",
        action="store",
        default=None,
        help="ã‚«ã‚¹ã‚¿ãƒ knowhowæƒ…å ±ã‚’ç›´æ¥æŒ‡å®šï¼ˆå…¨ãƒ†ã‚¹ãƒˆã«é©ç”¨ï¼‰"
    )
    parser.addoption(
        "--testsheet",
        action="store",
        default="testsheet.csv",
        help="ãƒ†ã‚¹ãƒˆã‚±ãƒ¼ã‚¹å®šç¾©CSVãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: testsheet.csvï¼‰"
    )
    parser.addoption(
        "--capabilities",
        action="store",
        default="capabilities.json",
        help="Appium capabilities JSONãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: capabilities.jsonï¼‰"
    )
    parser.addoption(
        "--mini-model",
        action="store_true",
        default=False,
        help="é«˜é€Ÿãƒ»ä½ã‚³ã‚¹ãƒˆã®Miniãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ç”¨ã™ã‚‹"
    )


@pytest.fixture(scope="session")
def custom_knowhow(request):
    """ã‚«ã‚¹ã‚¿ãƒ knowhowæƒ…å ±ã‚’å–å¾—ã™ã‚‹fixture
    
    å„ªå…ˆé †ä½:
    1. --knowhow-text ã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼ˆã‚³ãƒãƒ³ãƒ‰ãƒ©ã‚¤ãƒ³ã‹ã‚‰ç›´æ¥æŒ‡å®šï¼‰
    2. --knowhow ã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼ˆãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ã‹ã‚‰èª­ã¿è¾¼ã¿ï¼‰
    3. ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆï¼ˆKNOWHOW_INFOï¼‰
    """
    # ãƒ†ã‚­ã‚¹ãƒˆãŒç›´æ¥æŒ‡å®šã•ã‚ŒãŸå ´åˆï¼ˆæœ€å„ªå…ˆï¼‰
    knowhow_text = request.config.getoption("--knowhow-text")
    if knowhow_text:
        print(Fore.CYAN + "ğŸ“ ã‚«ã‚¹ã‚¿ãƒ knowhowï¼ˆç›´æ¥æŒ‡å®šï¼‰ã‚’ä½¿ç”¨ã—ã¾ã™")
        return knowhow_text
    
    # ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ãŒæŒ‡å®šã•ã‚ŒãŸå ´åˆ
    knowhow_path = request.config.getoption("--knowhow")
    if knowhow_path:
        # ç›¸å¯¾ãƒ‘ã‚¹ã®å ´åˆã¯ã‚«ãƒ¬ãƒ³ãƒˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªåŸºæº–ã§è§£æ±º
        if not os.path.isabs(knowhow_path):
            knowhow_path = os.path.join(os.getcwd(), knowhow_path)
        try:
            with open(knowhow_path, "r", encoding="utf-8") as f:
                knowhow_content = f.read()
            print(Fore.CYAN + f"ğŸ“ ã‚«ã‚¹ã‚¿ãƒ knowhowï¼ˆãƒ•ã‚¡ã‚¤ãƒ«: {knowhow_path}ï¼‰ã‚’ä½¿ç”¨ã—ã¾ã™")
            return knowhow_content
        except FileNotFoundError:
            print(Fore.RED + f"âš ï¸  è­¦å‘Š: knowhowãƒ•ã‚¡ã‚¤ãƒ« '{knowhow_path}' ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã‚’ä½¿ç”¨ã—ã¾ã™ã€‚")
        except Exception as e:
            print(Fore.RED + f"âš ï¸  è­¦å‘Š: knowhowãƒ•ã‚¡ã‚¤ãƒ«ã®èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}ã€‚ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã‚’ä½¿ç”¨ã—ã¾ã™ã€‚")
    
    # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ
    return KNOWHOW_INFO


@pytest.fixture(scope="session")
def testsheet_path(request):
    """ãƒ†ã‚¹ãƒˆã‚·ãƒ¼ãƒˆCSVãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹ã‚’å–å¾—ã™ã‚‹fixture
    
    --testsheet ã‚ªãƒ—ã‚·ãƒ§ãƒ³ã§æŒ‡å®šã•ã‚ŒãŸãƒ‘ã‚¹ã€ã¾ãŸã¯ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã® testsheet.csv ã‚’è¿”ã™
    """
    path = request.config.getoption("--testsheet")
    print(Fore.CYAN + f"ğŸ“‹ ãƒ†ã‚¹ãƒˆã‚·ãƒ¼ãƒˆCSV: {path}")
    return path


def pytest_configure(config):
    """pytestè¨­å®šæ™‚ã«ã‚°ãƒ­ãƒ¼ãƒãƒ«å¤‰æ•°ã‚’è¨­å®š"""
    global capabilities_path
    import sys
    
    # --mini-model ã‚ªãƒ—ã‚·ãƒ§ãƒ³ãŒæŒ‡å®šã•ã‚ŒãŸå ´åˆã€ç’°å¢ƒå¤‰æ•°ã‚’è¨­å®š
    if config.getoption("--mini-model"):
        os.environ["USE_MINI_MODEL"] = "1"
        # configãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã®ãƒ¢ãƒ‡ãƒ«è¨­å®šã‚’æ›´æ–°ï¼ˆãƒˆãƒƒãƒ—ãƒ¬ãƒ™ãƒ«ã§ã‚¤ãƒ³ãƒãƒ¼ãƒˆæ¸ˆã¿ã®cfgã‚’ä½¿ç”¨ï¼‰
        cfg.use_mini_model = True
        cfg.planner_model = cfg.MODEL_MINI
        cfg.execution_model = cfg.MODEL_MINI
        cfg.evaluation_model = cfg.MODEL_EVALUATION_MINI
        print(Fore.CYAN + "ğŸš€ Miniãƒ¢ãƒ‡ãƒ«ãƒ¢ãƒ¼ãƒ‰ã§å®Ÿè¡Œã—ã¾ã™")
    
    # ãƒ†ã‚¹ãƒˆã‚·ãƒ¼ãƒˆãƒ‘ã‚¹ã‚’ã‚°ãƒ­ãƒ¼ãƒãƒ«å¤‰æ•°ã¨ã—ã¦ä¿å­˜
    sys._pytest_testsheet_path = config.getoption("--testsheet")
    
    # capabilities ãƒ‘ã‚¹ã‚’è¨­å®šï¼ˆç›¸å¯¾ãƒ‘ã‚¹ã®å ´åˆã¯ã‚«ãƒ¬ãƒ³ãƒˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªåŸºæº–ã§è§£æ±ºï¼‰
    cap_path = config.getoption("--capabilities")
    if not os.path.isabs(cap_path):
        cap_path = os.path.join(os.getcwd(), cap_path)
    capabilities_path = cap_path


def pytest_collection_modifyitems(session, config, items):
    """pytest ãŒãƒ†ã‚¹ãƒˆã‚’åé›†ã—ãŸå¾Œã«å‘¼ã°ã‚Œã‚‹ï¼ˆ-k ãƒ•ã‚£ãƒ«ã‚¿é©ç”¨å¾Œï¼‰
    
    å„ãƒ†ã‚¹ãƒˆã‚¢ã‚¤ãƒ†ãƒ ã«å®Ÿè¡Œé †ã¨ç·æ•°ã‚’ä»˜ä¸ã™ã‚‹ã€‚
    ã“ã‚Œã«ã‚ˆã‚Š -k ã§çµã‚‰ã‚ŒãŸå®Ÿéš›ã®å®Ÿè¡Œãƒ†ã‚¹ãƒˆæ•°ã‚’æ­£ç¢ºã«å–å¾—ã§ãã‚‹ã€‚
    
    æ³¨æ„: ã“ã®ãƒ•ãƒƒã‚¯ã¯ deselect ãƒ•ã‚£ãƒ«ã‚¿é©ç”¨å¾Œã«å‘¼ã°ã‚Œã‚‹ãŸã‚ã€
    items ã«ã¯å®Ÿéš›ã«å®Ÿè¡Œã•ã‚Œã‚‹ãƒ†ã‚¹ãƒˆã®ã¿ãŒå«ã¾ã‚Œã‚‹ã€‚
    """
    import sys
    total = len(items)
    sys._pytest_total_tests = total
    sys._pytest_test_order = {}
    
    for i, item in enumerate(items, 1):
        # å„ãƒ†ã‚¹ãƒˆã«å®Ÿè¡Œé †ã‚’ä»˜ä¸
        item._test_progress_current = i
        item._test_progress_total = total
        # ãƒ†ã‚¹ãƒˆåã‹ã‚‰é †ç•ªã‚’å¼•ã‘ã‚‹ã‚ˆã†ã«ãƒãƒƒãƒ—ã‚‚ä½œæˆ
        sys._pytest_test_order[item.name] = i
    
    # Note: [PROGRESS] collected ã¯ pytest_collection_finish ã§å‡ºåŠ›


def pytest_collection_finish(session):
    """ãƒ†ã‚¹ãƒˆåé›†å®Œäº†å¾Œï¼ˆã™ã¹ã¦ã®ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°é©ç”¨å¾Œï¼‰ã«å‘¼ã°ã‚Œã‚‹"""
    import sys
    # session.items ã«ã¯æœ€çµ‚çš„ã«å®Ÿè¡Œã•ã‚Œã‚‹ãƒ†ã‚¹ãƒˆã®ã¿ãŒå«ã¾ã‚Œã‚‹
    total = len(session.items)
    sys._pytest_total_tests = total
    
    # å„ãƒ†ã‚¹ãƒˆã«æ­£ã—ã„é †ç•ªã‚’å†è¨­å®š
    for i, item in enumerate(session.items, 1):
        item._test_progress_current = i
        item._test_progress_total = total
        sys._pytest_test_order[item.name] = i
    
    print(Fore.CYAN + f"\n[PROGRESS] {{\"total\": {total}, \"status\": \"collected\"}}")


def pytest_runtest_setup(item):
    """å„ãƒ†ã‚¹ãƒˆå®Ÿè¡Œå‰ã«ç¾åœ¨ã®ãƒ†ã‚¹ãƒˆã‚¢ã‚¤ãƒ†ãƒ ã‚’ä¿å­˜"""
    import sys
    sys._pytest_current_item = item


def pytest_sessionstart(session):
    """ãƒ†ã‚¹ãƒˆã‚»ãƒƒã‚·ãƒ§ãƒ³é–‹å§‹æ™‚ã®å‡¦ç†"""
    print(Fore.CYAN + "\n" + "="*70)
    print(Fore.CYAN + "ğŸš€ Test Session Started")
    print(Fore.CYAN + "="*70)


def pytest_sessionfinish(session, exitstatus):
    """ãƒ†ã‚¹ãƒˆã‚»ãƒƒã‚·ãƒ§ãƒ³çµ‚äº†æ™‚ã«å…¨ä½“ã®èª²é‡‘æƒ…å ±ã‚’Allureãƒ¬ãƒãƒ¼ãƒˆã«æ›¸ãè¾¼ã‚€"""
    print(Fore.CYAN + "\n" + "="*70)
    print(Fore.CYAN + "ğŸ“Š Generating Global Token Usage Report")
    print(Fore.CYAN + "="*70)
    
    # ã‚°ãƒ­ãƒ¼ãƒãƒ«çµ±è¨ˆã®ãƒ†ã‚­ã‚¹ãƒˆã¯ã‚³ãƒ³ã‚½ãƒ¼ãƒ«ã«å‡ºåŠ›ã—ãªã„
    global_summary_text = TiktokenCountCallback.format_global_summary()
    
    # Allureãƒ¬ãƒãƒ¼ãƒˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®ç¢ºèª
    allure_results_dir = session.config.option.allure_report_dir
    if not allure_results_dir:
        # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã®allure-resultsãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ä½¿ç”¨
        allure_results_dir = "allure-results"
    
    if not os.path.exists(allure_results_dir):
        os.makedirs(allure_results_dir)
    
    # ã‚°ãƒ­ãƒ¼ãƒãƒ«ã‚µãƒãƒªãƒ¼ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
    global_summary = TiktokenCountCallback.get_global_summary()
    session_history = TiktokenCountCallback.get_global_history()
    
    # CSVãƒ•ã‚¡ã‚¤ãƒ«åã‚’ç”Ÿæˆï¼ˆã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ä»˜ãï¼‰
    csv_filename = f"token-usage-{time.strftime('%Y%m%d%H%M%S')}.csv"
    csv_file = os.path.join(allure_results_dir, csv_filename)
    
    # CSVãƒ•ã‚¡ã‚¤ãƒ«ã«ã‚»ãƒƒã‚·ãƒ§ãƒ³è©³ç´°ã‚’ä¿å­˜
    import csv
    with open(csv_file, "w", encoding="utf-8", newline='') as f:
        writer = csv.writer(f)
        # ãƒ˜ãƒƒãƒ€ãƒ¼è¡Œ
        writer.writerow([
            "Session Label",
            "Timestamp",
            "Total Invocations",
            "Total Tokens",
            "Input Tokens",
            "Output Tokens",
            "Cached Tokens",
            "Total Cost (USD)"
        ])
        
        # å„ã‚»ãƒƒã‚·ãƒ§ãƒ³ã®è©³ç´°
        for session in session_history:
            writer.writerow([
                session.get('session_label', ''),
                session.get('timestamp', ''),
                session.get('total_invocations', 0),
                session.get('total_tokens', 0),
                session.get('total_input_tokens', 0),
                session.get('total_output_tokens', 0),
                session.get('total_cached_tokens', 0),
                f"{session.get('total_cost_usd', 0.0):.6f}"
            ])
        
        # ã‚µãƒãƒªãƒ¼è¡Œï¼ˆç©ºè¡Œã®å¾Œã«è¿½åŠ ï¼‰
        writer.writerow([])
        writer.writerow([
            "TOTAL",
            "",
            global_summary.get('total_invocations', 0),
            global_summary.get('total_tokens', 0),
            global_summary.get('total_input_tokens', 0),
            global_summary.get('total_output_tokens', 0),
            global_summary.get('total_cached_tokens', 0),
            f"{global_summary.get('total_cost_usd', 0.0):.6f}"
        ])
    
    print(Fore.CYAN + f"âœ… Token usage CSV written to {csv_file}")
    
    # environment.propertiesã®å…ˆé ­ã«èª²é‡‘æƒ…å ±ã‚’è¿½åŠ 
    env_file = os.path.join(allure_results_dir, "environment.properties")
    
    # æ—¢å­˜ã®å†…å®¹ã‚’èª­ã¿è¾¼ã‚€
    existing_content = ""
    if os.path.exists(env_file):
        with open(env_file, "r", encoding="utf-8") as f:
            existing_content = f.read()
    
    # æ–°ã—ã„å†…å®¹ã‚’ä½œæˆï¼ˆå…ˆé ­ã«èª²é‡‘æƒ…å ±ï¼‰
    total_invocations = global_summary.get('total_invocations', 0)
    avg_cost = global_summary.get('total_cost_usd', 0.0) / total_invocations if total_invocations > 0 else 0.0
    
    with open(env_file, "w", encoding="utf-8") as f:
        # LLMèª²é‡‘æƒ…å ±ã‚’å…ˆé ­ã«æ›¸ãè¾¼ã¿
        f.write(f"LLM_totalCostUSD={global_summary.get('total_cost_usd', 0.0):.6f}\n")
        f.write(f"LLM_totalTokens={global_summary.get('total_tokens', 0)}\n")
        f.write(f"LLM_totalInvocations={global_summary.get('total_invocations', 0)}\n")
        f.write(f"LLM_avgCostPerCall={avg_cost:.6f}\n")
        f.write(f"BillingDashboardFile={csv_filename}\n")
        f.write("\n")
        
        # æ—¢å­˜ã®å†…å®¹ã‚’è¿½åŠ 
        f.write(existing_content)
    
    print(Fore.CYAN + f"âœ… Global token usage written to {env_file}")


async def evaluate_task_result(
    task_input: str, response: str, executed_steps: list = None, replanner_judgment: str = None, state_analysis: str = None, token_callback=None
) -> str:
    """ã‚¿ã‚¹ã‚¯çµæœã‚’æ§‹é€ åŒ–è©•ä¾¡ã— RESULT_PASS / RESULT_SKIP / RESULT_FAIL ã‚’å³å¯†è¿”å´ã™ã‚‹
    
    Args:
        task_input: å…ƒã®ã‚¿ã‚¹ã‚¯æŒ‡ç¤º
        response: æœ€çµ‚å¿œç­”
        executed_steps: å®Ÿè¡Œã•ã‚ŒãŸã‚¹ãƒ†ãƒƒãƒ—å±¥æ­´
        replanner_judgment: ãƒªãƒ—ãƒ©ãƒ³ãƒŠãƒ¼ãŒRESPONSEã¨åˆ¤æ–­ã—ãŸã¨ãã®å†…å®¹ï¼ˆstatus, reasonï¼‰
        state_analysis: ãƒªãƒ—ãƒ©ãƒ³ãƒŠãƒ¼ã«ã‚ˆã‚‹çŠ¶æ…‹åˆ†æçµæœ
        token_callback: ãƒˆãƒ¼ã‚¯ãƒ³ã‚«ã‚¦ãƒ³ã‚¿ãƒ¼ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯
    """
    # ä½¿ç”¨ãƒ¢ãƒ‡ãƒ«ã®æ±ºå®šï¼ˆå‹•çš„ã«å–å¾—ï¼‰
    model = cfg.evaluation_model

    # ãƒ¢ãƒ‡ãƒ«ã¯ç¾çŠ¶å›ºå®šï¼ˆç°¡ç´ åŒ–ï¼‰
    callbacks = [token_callback] if token_callback else []
    llm = ChatOpenAI(
        model=model,
        temperature=0,
        timeout=OPENAI_TIMEOUT,
        max_retries=OPENAI_MAX_RETRIES,
        callbacks=callbacks if callbacks else None
    )
    print(Fore.CYAN + f"è©•ä¾¡ç”¨ãƒ¢ãƒ‡ãƒ«: {model}")

    # å®Ÿè¡Œã‚¹ãƒ†ãƒƒãƒ—å±¥æ­´ã®æ–‡å­—åˆ—åŒ–
    steps_summary = ""
    if executed_steps:
        for i, step_info in enumerate(executed_steps, 1):
            success_mark = "âœ“" if step_info["success"] else "âœ—"
            steps_summary += f"{i}. {success_mark} {step_info['step']}\n"

    evaluation_prompt = f"""
ã‚ãªãŸã¯ãƒ†ã‚¹ãƒˆçµæœåˆ¤å®šã®ã‚¨ã‚­ã‚¹ãƒ‘ãƒ¼ãƒˆã§ã™ã€‚ä»¥ä¸‹ã‚’å³å¯†ã«æ¤œè¨¼ã— JSON ã®ã¿ã§è¿”ç­”ã—ã¦ãã ã•ã„ã€‚

# å…ƒã‚¿ã‚¹ã‚¯æŒ‡ç¤º:
{task_input}

# å®Ÿè¡Œã‚¹ãƒ†ãƒƒãƒ—å±¥æ­´:
{steps_summary or '(ãªã—)'}

# ç¾åœ¨ã®ç”»é¢çŠ¶æ…‹åˆ†æçµæœ:
{state_analysis}

# ãƒªãƒ—ãƒ©ãƒ³ãƒŠãƒ¼ã®åˆ¤æ–­çµæœ:
{replanner_judgment}

# æœ€çµ‚å¿œç­”:
{response}

# åˆ¤å®šè¦å‰‡:
1. {RESULT_PASS} ã®æ¡ä»¶:
    - æŒ‡ç¤ºæ‰‹é †ã‚’éä¸è¶³ãªãå®Ÿè¡Œ
    - ä¸è¦/é€¸è„±ã‚¹ãƒ†ãƒƒãƒ—ãªã—
    - å¿œç­”å†…ã«æœŸå¾…åŸºæº–ã¸ç›´æ¥å¯¾å¿œã™ã‚‹å…·ä½“çš„æ ¹æ‹ ï¼ˆè¦ç´ ID / text / ç”»åƒèª¬æ˜ / æ“ä½œçµæœï¼‰ãŒå­˜åœ¨
    - ç”»åƒè©•ä¾¡ãŒå¿…è¦ãªã‚±ãƒ¼ã‚¹ã§ã¯ãã®æ ¹æ‹ ã‚’è¨€åŠ
    - ä»¥ä¸‹ã®å¯¾å¿œã¯ã€æœ¬ã‚¿ã‚¹ã‚¯ã®è©•ä¾¡å¯¾è±¡å¤–ã¨ã—ã€ä¸è¦ã‚ã‚‹ã„ã¯é€¸è„±ã‚¹ãƒ†ãƒƒãƒ—ã¨ã—ã¦æ‰±ã‚ãªã„ï¼šãƒ—ãƒ©ã‚¤ãƒã‚·ãƒ¼ãƒãƒªã‚·ãƒ¼ã€ãƒ‡ã‚£ã‚¹ã‚¯ãƒ¬ãƒ¼ãƒãƒ¼ã€åˆæœŸè¨­å®šãƒ€ã‚¤ã‚¢ãƒ­ã‚°ã€åºƒå‘Šãƒ€ã‚¤ã‚¢ãƒ­ã‚° ãªã©

2. {RESULT_SKIP} ã®æ¡ä»¶:
    - æ ¹æ‹ ãŒæ›–æ˜§ / åè¨¼ä¸èƒ½ / ä¸»è¦³çš„
    - å¿…è¦æ‰‹é †ä¸è¶³ or ä½™è¨ˆãªæ“ä½œã‚ã‚Š
    - ãƒ­ã‚±ãƒ¼ã‚¿ / ç”»åƒç¢ºèªãŒå¿…è¦ãªã®ã«ä¸ååˆ†
    - ã‚¨ãƒ©ãƒ¼ / ä¸æ•´åˆ / åˆ¤å®šå›°é›£

# å‡ºåŠ›ä»•æ§˜:
å³å¯†JSON
"""
    print(Fore.CYAN + "[evaluate_task_result] è©•ä¾¡ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ç”Ÿæˆ")
    print(Fore.CYAN + evaluation_prompt)

    try:
        messages = [
            SystemMessage(content="ã‚ãªãŸã¯æ­£ç¢ºãªãƒ†ã‚¹ãƒˆçµæœåˆ¤å®šã‚’è¡Œã†ã‚¨ã‚­ã‚¹ãƒ‘ãƒ¼ãƒˆã§ã™ã€‚JSONã®ã¿è¿”ç­”ã€‚"),
            HumanMessage(content=evaluation_prompt),
        ]
        structured_llm = llm.with_structured_output(EvaluationResult)
        
        # track_query()ã§ã‚¯ã‚¨ãƒªã”ã¨ã®ãƒˆãƒ¼ã‚¯ãƒ³ä½¿ç”¨é‡ã‚’è¨˜éŒ²
        with token_callback.track_query():
            eval_struct: EvaluationResult = await structured_llm.ainvoke(messages)

        status = eval_struct.status
        reason = eval_struct.reason.strip()

        color = Fore.GREEN if status == RESULT_PASS else Fore.RED
        print(color + f"[evaluate_task_result] status={status}")

        return f"{status}\nåˆ¤å®šç†ç”±:\n{reason}"
    except Exception as e:
        err_type = type(e).__name__
        print(Fore.RED + f"[evaluate_task_result] Exception: {err_type}: {e}")
        allure.attach(
            f"Exception Type: {err_type}\nLocation: evaluate_task_result\nMessage: {e}",
            name="âŒ evaluate_task_result Exception",
            attachment_type=allure.attachment_type.TEXT
        )
        log_openai_error_to_allure(
            error_type=err_type,
            location="evaluate_task_result",
            model=model,
            error=e
        )
        return f"{RESULT_SKIP}\nåˆ¤å®šç†ç”±: è©•ä¾¡ä¸­ã‚¨ãƒ©ãƒ¼ ({err_type})"


# --- ãƒ˜ãƒ«ãƒ‘ãƒ¼é–¢æ•° ---
# (generate_screen_info ã¯ utils.screen_helper ã«ç§»å‹•)


# --- ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼é–¢æ•°ã®å®šç¾© ---
async def agent_session(no_reset: bool = True, dont_stop_app_on_reset: bool = False, knowhow: str = KNOWHOW_INFO):
    """MCPã‚»ãƒƒã‚·ãƒ§ãƒ³å†…ã§graphã‚’ä½œæˆã—ã€ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚’ç¶­æŒã—ãªãŒã‚‰yieldã™ã‚‹

    Args:
        no_reset: appium:noResetã®è¨­å®šå€¤ã€‚Trueï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆï¼‰ã¯ãƒªã‚»ãƒƒãƒˆãªã—ã€Falseã¯ãƒªã‚»ãƒƒãƒˆã‚ã‚Šã€‚
        knowhow: ãƒã‚¦ãƒã‚¦æƒ…å ±ã€‚ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã¯KNOWHOW_INFOã€ã‚«ã‚¹ã‚¿ãƒ knowhowã‚’æ¸¡ã™ã“ã¨ã‚‚å¯èƒ½ã€‚
    """
    
    options = UiAutomator2Options()
    capabilities = {}

    try:
        with open(capabilities_path, "r") as f:
            capabilities = json.load(f)

            # ä»»æ„ã®è¿½åŠ è¨­å®š
            capabilities.update({
                "appium:waitForIdleTimeout": 1000, # é«˜é€ŸåŒ–ã®ãŸã‚å¾…æ©Ÿã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆã‚’1ç§’ã«è¨­å®š
                "appium:noReset": no_reset, # noResetãŒTrueãªã‚‰ã‚¢ãƒ—ãƒªã‚’ãƒªã‚»ãƒƒãƒˆã—ãªã„
                "appium:appWaitActivity": "*", # ã™ã¹ã¦ã®ã‚¢ã‚¯ãƒ†ã‚£ãƒ“ãƒ†ã‚£ã‚’å¾…æ©Ÿ
                "appium:autoGrantPermissions": True, # æ¨©é™ã‚’è‡ªå‹•ä»˜ä¸
                "appium:dontStopAppOnReset": dont_stop_app_on_reset, # ã‚»ãƒƒã‚·ãƒ§ãƒ³ãƒªã‚»ãƒƒãƒˆæ™‚ã«ã‚¢ãƒ—ãƒªã‚’åœæ­¢ã—ãªã„
            })

            # Apply all capabilities from the loaded dictionary
            for key, value in capabilities.items():
                # Set each capability dynamically
                options.set_capability(key, value)
    except FileNotFoundError:
        print(
            f"è­¦å‘Š: {capabilities_path} ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚"
        )
        raise

    except json.JSONDecodeError:
        print(
            f"è­¦å‘Š: {capabilities_path} ã®JSONå½¢å¼ãŒç„¡åŠ¹ã§ã™ã€‚ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆè¨­å®šã§å®Ÿè¡Œã—ã¾ã™ã€‚"
        )
        raise

    

    try:
        async with appium_driver(options) as driver:
            # æœ€åˆã®ã‚»ãƒƒã‚·ãƒ§ãƒ³é–‹å§‹æ™‚ã«ãƒ‡ãƒã‚¤ã‚¹æƒ…å ±ã‚’å–å¾—ã—ã¦æ›¸ãè¾¼ã‚€
            await write_device_info_once(
                driver=driver,
                capabilities_path=capabilities_path,
                appium_tools_func=appium_tools
            )

            # å¿…è¦ãªãƒ„ãƒ¼ãƒ«ã‚’å–å¾—ï¼ˆãƒªã‚¹ãƒˆã‹ã‚‰åå‰ã§æ¤œç´¢ï¼‰
            tools_list = appium_tools()
            tools_dict = {tool.name: tool for tool in tools_list}
            screenshot_tool = tools_dict.get("take_screenshot")
            generate_locators = tools_dict.get("get_page_source")
            activate_app = tools_dict.get("activate_app")
            terminate_app = tools_dict.get("terminate_app")
            # noReset=True ã®å ´åˆã€appPackageã§æŒ‡å®šã•ã‚ŒãŸã‚¢ãƒ—ãƒªã‚’å¼·åˆ¶èµ·å‹•
            if no_reset:
                app_package = capabilities.get("appium:appPackage")
                if app_package:
                    print(Fore.CYAN + f"noReset=True: ã‚¢ãƒ—ãƒªã‚’å¼·åˆ¶èµ·å‹•ã—ã¾ã™ (appPackage={app_package})")
                    try:
                        activate_result = await activate_app.ainvoke({"app_id": app_package})
                        print(f"appium_activate_appçµæœ: {activate_result}")
                        print("ã‚¢ãƒ—ãƒªèµ·å‹•å¾…æ©Ÿä¸­... (3ç§’)")
                        await asyncio.sleep(3)
                    except Exception as e:
                        print(Fore.YELLOW + f"âš ï¸  appium_activate_appå®Ÿè¡Œã‚¨ãƒ©ãƒ¼: {e}")
                else:
                    print(Fore.YELLOW + "âš ï¸  appPackageãŒæŒ‡å®šã•ã‚Œã¦ã„ãªã„ãŸã‚ã€ã‚¢ãƒ—ãƒªèµ·å‹•ã‚’ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™")
            else:
                # noReset=False ã®å ´åˆã¯é€šå¸¸é€šã‚Šå¾…æ©Ÿã®ã¿
                print("ã‚¢ãƒ—ãƒªèµ·å‹•å¾…æ©Ÿä¸­... (3ç§’)")
                await asyncio.sleep(3)

            # ç’°å¢ƒå¤‰æ•°ã§ãƒ¢ãƒ‡ãƒ«é¸æŠï¼ˆå‹•çš„ã«å–å¾—ï¼‰
            print(Fore.CYAN + f"ä½¿ç”¨ãƒ¢ãƒ‡ãƒ«: {cfg.execution_model}")

            # ãƒˆãƒ¼ã‚¯ãƒ³ã‚«ã‚¦ãƒ³ã‚¿ãƒ¼ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯ã‚’ä½œæˆ
            token_callback = TiktokenCountCallback(model=cfg.execution_model)

            # ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚¨ã‚°ã‚¼ã‚­ãƒ¥ãƒ¼ã‚¿ãƒ¼ã‚’ä½œæˆï¼ˆã‚«ã‚¹ã‚¿ãƒ knowhowã‚’ä½¿ç”¨ï¼‰
            llm = ChatOpenAI(
                model=cfg.execution_model,
                temperature=0,
                timeout=OPENAI_TIMEOUT,
                max_retries=OPENAI_MAX_RETRIES,
                callbacks=[token_callback]
            )
            prompt = f"""ã‚ãªãŸã¯è¦ªåˆ‡ãªAndroidã‚¢ãƒ—ãƒªã‚’è‡ªå‹•æ“ä½œã™ã‚‹ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚ä¸ãˆã‚‰ã‚ŒãŸã‚¿ã‚¹ã‚¯ã‚’æ­£ç¢ºã«å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚\n{knowhow}\n"""

            agent_executor = create_agent(llm, appium_tools(), system_prompt=prompt)
            print(Fore.CYAN + f"Agent Executorç”¨ãƒ¢ãƒ‡ãƒ«: {cfg.execution_model}")

            planner = SimplePlanner(
                knowhow, 
                model_name=cfg.planner_model,
                token_callback=token_callback
            )

            # LLMã«æ¸¡ã•ã‚Œã‚‹knowhowæƒ…å ±ã‚’è¡¨ç¤º
            print(Fore.MAGENTA + "=" * 60)
            print(Fore.MAGENTA + "ã€LLMã«æ¸¡ã•ã‚Œã‚‹knowhowæƒ…å ±ã€‘")
            print(Fore.MAGENTA + "=" * 60)
            print(Fore.CYAN + knowhow)
            print(Fore.MAGENTA + "=" * 60)

            # ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼é–¢æ•°ã‚’ä½œæˆï¼ˆã‚»ãƒƒã‚·ãƒ§ãƒ³å†…ã®ãƒ„ãƒ¼ãƒ«ã‚’ä½¿ç”¨ï¼‰
            max_replan_count = 20
            
            # evaluate_task_resultã‚’ãƒ©ãƒƒãƒ—ã—ã¦token_callbackã‚’æ¸¡ã™
            async def evaluate_with_token_callback(task_input, response, executed_steps, replanner_judgment=None, state_analysis=None):
                return await evaluate_task_result(task_input, response, executed_steps, replanner_judgment, state_analysis, token_callback)
            
            execute_step, plan_step, replan_step, should_end = (
                create_workflow_functions(
                    planner,
                    agent_executor,
                    screenshot_tool,
                    generate_locators,
                    evaluate_with_token_callback,
                    max_replan_count,
                    knowhow,
                    token_callback,
                )
            )

            # ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã‚’æ§‹ç¯‰
            workflow = StateGraph(PlanExecute)
            workflow.add_node("planner", plan_step)
            workflow.add_node("agent", execute_step)
            workflow.add_node("replan", replan_step)
            workflow.add_edge(START, "planner")
            workflow.add_edge("planner", "agent")
            workflow.add_edge("agent", "replan")
            workflow.add_conditional_edges("replan", should_end, ["agent", END])
            graph = workflow.compile()

            # graphã¨past_stepsã‚’yieldã—ã¦ã€ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚’ç¶­æŒ    
            try:
                yield graph
            finally:
                # æœ€å°é™: ã‚»ãƒƒã‚·ãƒ§ãƒ³ã®ã‚°ãƒ­ãƒ¼ãƒãƒ«ä¿å­˜ã®ã¿ï¼ˆè¡¨ç¤ºã‚„æ·»ä»˜ã¯ã—ãªã„ï¼‰
                
                # ã‚°ãƒ­ãƒ¼ãƒãƒ«çµ±è¨ˆã«ä¿å­˜ï¼ˆãƒ†ã‚¹ãƒˆã‚±ãƒ¼ã‚¹IDã‚’ãƒ©ãƒ™ãƒ«ã¨ã—ã¦ä½¿ç”¨ï¼‰
                try:
                    # pytest ã®ç¾åœ¨ã®ãƒ†ã‚¹ãƒˆã‚¢ã‚¤ãƒ†ãƒ ã‹ã‚‰ãƒ†ã‚¹ãƒˆIDã‚’å–å¾—
                    import sys
                    test_id = "Unknown Test"
                    if hasattr(sys, '_pytest_current_item'):
                        test_id = sys._pytest_current_item.nodeid
                    
                    # ã‚°ãƒ­ãƒ¼ãƒãƒ«å±¥æ­´ã«ä¿å­˜
                    token_callback.save_session_to_global(test_id)
                except Exception:
                    pass
                
                # ã‚»ãƒƒã‚·ãƒ§ãƒ³çµ‚äº†å‰ã«ã‚¢ãƒ—ãƒªã‚’çµ‚äº†
                app_package = capabilities.get("appium:appPackage")
                dont_stop_app_on_reset = capabilities.get("appium:dontStopAppOnReset")
                if app_package and not dont_stop_app_on_reset:
                    print(Fore.CYAN + f"ã‚»ãƒƒã‚·ãƒ§ãƒ³çµ‚äº†: ã‚¢ãƒ—ãƒªã‚’çµ‚äº†ã—ã¾ã™ (appPackage={app_package})")
                    try:
                        terminate_result = await terminate_app.ainvoke({"app_id": app_package})
                        print(f"appium_terminate_appçµæœ: {terminate_result}")
                    except Exception as e:
                        error_msg = str(e)
                        # NoSuchDriverError ã‚„ session terminated ã‚¨ãƒ©ãƒ¼ã¯è­¦å‘Šãƒ¬ãƒ™ãƒ«ã§æ‰±ã†
                        if "NoSuchDriverError" in error_msg or "session is either terminated or not started" in error_msg or "session" in error_msg.lower():
                            print(Fore.YELLOW + f"âš ï¸  ã‚»ãƒƒã‚·ãƒ§ãƒ³ãŒæ—¢ã«çµ‚äº†ã—ã¦ã„ã¾ã™: {e}")
                        else:
                            print(Fore.YELLOW + f"âš ï¸  appium_terminate_appå®Ÿè¡Œã‚¨ãƒ©ãƒ¼: {e}")

    except Exception as e:
        error_msg = str(e)
        # NoSuchDriverError ã‚„ session terminated ã‚¨ãƒ©ãƒ¼ã¯æƒ…å ±ãƒ¬ãƒ™ãƒ«ã§æ‰±ã†
        if "NoSuchDriverError" in error_msg or "session is either terminated or not started" in error_msg:
            print(Fore.YELLOW + f"âš ï¸  agent_session: ã‚»ãƒƒã‚·ãƒ§ãƒ³ãŒæ—¢ã«çµ‚äº†ã—ã¦ã„ã¾ã™: {e}")
        else:
            print(Fore.RED + f"agent_sessionã§ã‚¨ãƒ©ãƒ¼: {e}")
            raise e
    finally:
        print("ã‚»ãƒƒã‚·ãƒ§ãƒ³çµ‚äº†")


class SmartestiRoid:
    """ãƒ†ã‚¹ãƒˆç”¨ã®Plan-and-Executeã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚¯ãƒ©ã‚¹"""

    def __init__(self, agent_session, no_reset: bool = True, dont_stop_app_on_reset: bool = False, knowhow: str = KNOWHOW_INFO):
        self.agent_session = agent_session
        self.no_reset = no_reset
        self.dont_stop_app_on_reset = dont_stop_app_on_reset
        self.knowhow = knowhow  # ãƒã‚¦ãƒã‚¦æƒ…å ±ã‚’ä¿æŒ

    async def validate_task(
        self,
        steps: str,
        expected: str = "",
        knowhow: Optional[str] = None,
    ) -> str:
        """
        ã‚¿ã‚¹ã‚¯ã‚’å®Ÿè¡Œã—ã¦çµæœã‚’æ¤œè¨¼ã™ã‚‹
        
        Args:
            task: å®Ÿè¡Œã™ã‚‹ã‚¿ã‚¹ã‚¯
            ignore_case: å¤§æ–‡å­—å°æ–‡å­—ã‚’ç„¡è¦–ã™ã‚‹ã‹
            knowhow: ã‚«ã‚¹ã‚¿ãƒ knowhowæƒ…å ±ï¼ˆNoneã®å ´åˆã¯ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã®knowhowã‚’ä½¿ç”¨ï¼‰
        """
        config = {"recursion_limit": 50}

        # knowhowã®æ±ºå®š: ãƒ¡ã‚½ãƒƒãƒ‰å¼•æ•° > ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹å¤‰æ•° > ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ
        effective_knowhow = knowhow if knowhow is not None else self.knowhow

        # ã‚«ã‚¹ã‚¿ãƒ knowhowã‚’ä½¿ç”¨ã™ã‚‹å ´åˆã€æ–°ã—ã„ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚’ä½œæˆ
        async for graph in self.agent_session(self.no_reset, self.dont_stop_app_on_reset, effective_knowhow):
            # state["input"]ã«ã¯ç´”ç²‹ãªã‚¿ã‚¹ã‚¯ã®ã¿ã‚’æ¸¡ã™
            # knowhowã¯å„LLMï¼ˆSimplePlannerã€agent_executorï¼‰ãŒæ—¢ã«æŒã£ã¦ã„ã‚‹
            task = (
                f"ãƒ†ã‚¹ãƒˆå®Ÿæ–½æ‰‹é †:{steps}\n\n"
                f"ãƒ†ã‚¹ãƒˆåˆå¦åˆ¤å®šåŸºæº–:{expected}\n"
            )
            inputs = {"input": task}
            
            if knowhow is not None:
                print(Fore.YELLOW + f"ã‚«ã‚¹ã‚¿ãƒ knowhowæƒ…å ±ã‚’ä½¿ç”¨: {knowhow[:100]}...")

            print(Fore.CYAN + "=== Plan-and-Execute Agent é–‹å§‹ ===")
            try:
                final_result = {"response": ""}
                async for event in graph.astream(inputs, config=config):
                    for k, v in event.items():
                        if k != "__end__":
                            print(Fore.BLUE + str(v))
                            final_result = v

            except Exception as e:
                print(Fore.RED + f"å®Ÿè¡Œä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
                allure.attach(
                    f"ãƒ†ã‚¹ãƒˆå®Ÿè¡Œä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ:\n{e}",
                    name="âŒ Test Execution Error",
                    attachment_type=allure.attachment_type.TEXT,
                )
                assert False, f"ãƒ†ã‚¹ãƒˆå®Ÿè¡Œä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}"
            finally:
                print(Fore.CYAN + "=== Plan-and-Execute Agent çµ‚äº† ===")
            # async forãƒ«ãƒ¼ãƒ—ã¯ä¸€åº¦ã ã‘å®Ÿè¡Œã•ã‚Œã‚‹ã®ã§breakãŒä¸è¦

        # validation
        result_text = final_result.get("response", None)
        assert result_text is not None, "Agent did not return a final result."

        # RESULT_SKIPãŒå«ã¾ã‚Œã¦ã„ã‚‹å ´åˆã¯ã€pytestã§skipã™ã‚‹
        if RESULT_SKIP in result_text:
            pytest.skip("ã“ã®ãƒ†ã‚¹ãƒˆã¯å‡ºåŠ›çµæœã®ç›®è¦–ç¢ºèªãŒå¿…è¦ã§ã™")

        if RESULT_PASS:
            result_to_check = result_text.lower()
            substring_to_check = (
                RESULT_PASS.lower()
            )
            assert substring_to_check in result_to_check, (
                f"Assertion failed: Expected '{RESULT_PASS}' not found in agent result: '{result_text}'"
            )
        return result_text
