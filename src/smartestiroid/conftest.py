from typing import Dict, Any, Optional

from langchain_openai import ChatOpenAI
from .utils.structured_logger import SLog, LogCategory, LogEvent
from langchain.agents import create_agent
from langgraph.graph import StateGraph, START, END
from langchain_core.messages import HumanMessage, SystemMessage
from appium.options.android import UiAutomator2Options
import base64
from PIL import Image
import io
import allure
import pytest
import json
import os
import asyncio
import time

from .appium_tools import appium_driver, appium_tools, set_verify_model
from .appium_tools.token_counter import TiktokenCountCallback

# Import from newly created modules
from .models import (
    PlanExecute, Plan, Response, Act, DecisionResult, EvaluationResult
)
from .config import (
    OPENAI_TIMEOUT, OPENAI_MAX_RETRIES,
    MODEL_STANDARD, MODEL_MINI, MODEL_EVALUATION, MODEL_EVALUATION_MINI,
    RESULT_PASS, RESULT_SKIP, RESULT_FAIL,
    KNOWHOW_INFO
)
# ãƒ¢ãƒ‡ãƒ«å¤‰æ•°ï¼ˆplanner_modelç­‰ï¼‰ã¯ pytest_configure ã§å‹•çš„ã«å¤‰æ›´ã•ã‚Œã‚‹ãŸã‚ã€
# ç›´æ¥ã‚¤ãƒ³ãƒãƒ¼ãƒˆã›ãš cfg.planner_model ã®ã‚ˆã†ã«å‚ç…§ã™ã‚‹ï¼ˆconfig.py ã®ã‚³ãƒ¡ãƒ³ãƒˆå‚ç…§ï¼‰
from . import config as cfg
from .workflow import create_workflow_functions
from .utils.allure_logger import log_openai_error_to_allure
from .utils.device_info import write_device_info_once
from .agents import SimplePlanner


# ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ã®ãƒ«ãƒ¼ãƒˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
PACKAGE_DIR = os.path.dirname(os.path.abspath(__file__))

# ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã®capabilitiesãƒ‘ã‚¹ï¼ˆpytest_configureã§æ›´æ–°ã•ã‚Œã‚‹ï¼‰
capabilities_path = os.path.join(os.getcwd(), "capabilities.json")


# Pytest hooks for command-line options
def pytest_addoption(parser):
    """pytest ã‚³ãƒãƒ³ãƒ‰ãƒ©ã‚¤ãƒ³ã‚ªãƒ—ã‚·ãƒ§ãƒ³ã‚’è¿½åŠ """
    parser.addoption(
        "--knowhow",
        action="store",
        default=None,
        help="ã‚«ã‚¹ã‚¿ãƒ knowhowæƒ…å ±ã®ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ï¼ˆå…¨ãƒ†ã‚¹ãƒˆã«é©ç”¨ï¼‰"
    )
    parser.addoption(
        "--knowhow-text",
        action="store",
        default=None,
        help="ã‚«ã‚¹ã‚¿ãƒ knowhowæƒ…å ±ã‚’ç›´æ¥æŒ‡å®šï¼ˆå…¨ãƒ†ã‚¹ãƒˆã«é©ç”¨ï¼‰"
    )
    parser.addoption(
        "--testsheet",
        action="store",
        default="testsheet.csv",
        help="ãƒ†ã‚¹ãƒˆã‚±ãƒ¼ã‚¹å®šç¾©CSVãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: testsheet.csvï¼‰"
    )
    parser.addoption(
        "--capabilities",
        action="store",
        default="capabilities.json",
        help="Appium capabilities JSONãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: capabilities.jsonï¼‰"
    )
    parser.addoption(
        "--mini-model",
        action="store_true",
        default=False,
        help="é«˜é€Ÿãƒ»ä½ã‚³ã‚¹ãƒˆã®Miniãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ç”¨ã™ã‚‹"
    )
    parser.addoption(
        "--test-range",
        action="store",
        default=None,
        help="ãƒ†ã‚¹ãƒˆIDã®ç¯„å›²ã‚’æŒ‡å®š (ä¾‹: 0025-0030,0040-0045,0050)"
    )


@pytest.fixture(scope="session")
def custom_knowhow(request):
    """ã‚«ã‚¹ã‚¿ãƒ knowhowæƒ…å ±ã‚’å–å¾—ã™ã‚‹fixture
    
    å„ªå…ˆé †ä½:
    1. --knowhow-text ã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼ˆã‚³ãƒãƒ³ãƒ‰ãƒ©ã‚¤ãƒ³ã‹ã‚‰ç›´æ¥æŒ‡å®šï¼‰
    2. --knowhow ã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼ˆãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ã‹ã‚‰èª­ã¿è¾¼ã¿ï¼‰
    3. ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆï¼ˆKNOWHOW_INFOï¼‰
    """
    # ãƒ†ã‚­ã‚¹ãƒˆãŒç›´æ¥æŒ‡å®šã•ã‚ŒãŸå ´åˆï¼ˆæœ€å„ªå…ˆï¼‰
    knowhow_text = request.config.getoption("--knowhow-text")
    if knowhow_text:
        SLog.info(LogCategory.CONFIG, LogEvent.UPDATE, {"source": "command_line"}, "ã‚«ã‚¹ã‚¿ãƒ knowhowï¼ˆç›´æ¥æŒ‡å®šï¼‰ã‚’ä½¿ç”¨ã—ã¾ã™")
        return knowhow_text
    
    # ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ãŒæŒ‡å®šã•ã‚ŒãŸå ´åˆ
    knowhow_path = request.config.getoption("--knowhow")
    if knowhow_path:
        # ç›¸å¯¾ãƒ‘ã‚¹ã®å ´åˆã¯ã‚«ãƒ¬ãƒ³ãƒˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªåŸºæº–ã§è§£æ±º
        if not os.path.isabs(knowhow_path):
            knowhow_path = os.path.join(os.getcwd(), knowhow_path)
        try:
            with open(knowhow_path, "r", encoding="utf-8") as f:
                knowhow_content = f.read()
            SLog.info(LogCategory.CONFIG, LogEvent.UPDATE, {"source": "file", "path": knowhow_path}, f"ã‚«ã‚¹ã‚¿ãƒ knowhowï¼ˆãƒ•ã‚¡ã‚¤ãƒ«: {knowhow_path}ï¼‰ã‚’ä½¿ç”¨ã—ã¾ã™")
            return knowhow_content
        except FileNotFoundError:
            SLog.warn(LogCategory.CONFIG, LogEvent.FAIL, {"path": knowhow_path}, f"knowhowãƒ•ã‚¡ã‚¤ãƒ« '{knowhow_path}' ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã‚’ä½¿ç”¨ã—ã¾ã™ã€‚")
        except Exception as e:
            SLog.warn(LogCategory.CONFIG, LogEvent.FAIL, {"path": knowhow_path, "error": str(e)}, f"knowhowãƒ•ã‚¡ã‚¤ãƒ«ã®èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}ã€‚ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã‚’ä½¿ç”¨ã—ã¾ã™ã€‚")
    
    # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ
    return KNOWHOW_INFO


@pytest.fixture(scope="session")
def testsheet_path(request):
    """ãƒ†ã‚¹ãƒˆã‚·ãƒ¼ãƒˆCSVãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹ã‚’å–å¾—ã™ã‚‹fixture
    
    --testsheet ã‚ªãƒ—ã‚·ãƒ§ãƒ³ã§æŒ‡å®šã•ã‚ŒãŸãƒ‘ã‚¹ã€ã¾ãŸã¯ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã® testsheet.csv ã‚’è¿”ã™
    """
    path = request.config.getoption("--testsheet")
    SLog.info(LogCategory.CONFIG, LogEvent.UPDATE, {"testsheet": path}, f"ãƒ†ã‚¹ãƒˆã‚·ãƒ¼ãƒˆCSV: {path}")
    return path


def pytest_configure(config):
    """pytestè¨­å®šæ™‚ã«ã‚°ãƒ­ãƒ¼ãƒãƒ«å¤‰æ•°ã‚’è¨­å®š"""
    global capabilities_path
    import sys
    
    # --mini-model ã‚ªãƒ—ã‚·ãƒ§ãƒ³ãŒæŒ‡å®šã•ã‚ŒãŸå ´åˆã€ç’°å¢ƒå¤‰æ•°ã‚’è¨­å®š
    if config.getoption("--mini-model"):
        os.environ["USE_MINI_MODEL"] = "1"
        # configãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã®ãƒ¢ãƒ‡ãƒ«è¨­å®šã‚’æ›´æ–°ï¼ˆãƒˆãƒƒãƒ—ãƒ¬ãƒ™ãƒ«ã§ã‚¤ãƒ³ãƒãƒ¼ãƒˆæ¸ˆã¿ã®cfgã‚’ä½¿ç”¨ï¼‰
        cfg.use_mini_model = True
        cfg.planner_model = cfg.MODEL_MINI
        cfg.execution_model = cfg.MODEL_MINI
        cfg.evaluation_model = cfg.MODEL_EVALUATION_MINI
        # verify_screen_content ã®ãƒ¢ãƒ‡ãƒ«ã‚‚æ›´æ–°
        set_verify_model(cfg.MODEL_MINI)
        SLog.info(LogCategory.CONFIG, LogEvent.UPDATE, {"mode": "mini"}, "Miniãƒ¢ãƒ‡ãƒ«ãƒ¢ãƒ¼ãƒ‰ã§å®Ÿè¡Œã—ã¾ã™")
    
    # ãƒ†ã‚¹ãƒˆã‚·ãƒ¼ãƒˆãƒ‘ã‚¹ã‚’ã‚°ãƒ­ãƒ¼ãƒãƒ«å¤‰æ•°ã¨ã—ã¦ä¿å­˜
    sys._pytest_testsheet_path = config.getoption("--testsheet")
    
    # capabilities ãƒ‘ã‚¹ã‚’è¨­å®šï¼ˆç›¸å¯¾ãƒ‘ã‚¹ã®å ´åˆã¯ã‚«ãƒ¬ãƒ³ãƒˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªåŸºæº–ã§è§£æ±ºï¼‰
    cap_path = config.getoption("--capabilities")
    if not os.path.isabs(cap_path):
        cap_path = os.path.join(os.getcwd(), cap_path)
    capabilities_path = cap_path


def _parse_test_range(range_str: str) -> set:
    """ãƒ†ã‚¹ãƒˆç¯„å›²æ–‡å­—åˆ—ã‚’ãƒ‘ãƒ¼ã‚¹ã—ã¦ãƒ†ã‚¹ãƒˆIDç•ªå·ã®ã‚»ãƒƒãƒˆã‚’è¿”ã™
    
    Args:
        range_str: ç¯„å›²æŒ‡å®šæ–‡å­—åˆ— (ä¾‹: "0025-0030,0040-0045,0050")
    
    Returns:
        ãƒ†ã‚¹ãƒˆIDç•ªå·ã®ã‚»ãƒƒãƒˆ (ä¾‹: {25, 26, 27, 28, 29, 30, 40, 41, ...})
    """
    result = set()
    for part in range_str.split(","):
        part = part.strip()
        if "-" in part:
            # ç¯„å›²æŒ‡å®š: "0025-0030"
            start, end = part.split("-", 1)
            try:
                start_num = int(start)
                end_num = int(end)
                for i in range(start_num, end_num + 1):
                    result.add(i)
            except ValueError:
                pass  # ç„¡åŠ¹ãªç¯„å›²ã¯ç„¡è¦–
        else:
            # å˜ä¸€æŒ‡å®š: "0050"
            try:
                result.add(int(part))
            except ValueError:
                pass
    return result


def pytest_collection_modifyitems(session, config, items):
    """pytest ãŒãƒ†ã‚¹ãƒˆã‚’åé›†ã—ãŸå¾Œã«å‘¼ã°ã‚Œã‚‹ï¼ˆ-k ãƒ•ã‚£ãƒ«ã‚¿é©ç”¨å¾Œï¼‰
    
    å„ãƒ†ã‚¹ãƒˆã‚¢ã‚¤ãƒ†ãƒ ã«å®Ÿè¡Œé †ã¨ç·æ•°ã‚’ä»˜ä¸ã™ã‚‹ã€‚
    ã“ã‚Œã«ã‚ˆã‚Š -k ã§çµã‚‰ã‚ŒãŸå®Ÿéš›ã®å®Ÿè¡Œãƒ†ã‚¹ãƒˆæ•°ã‚’æ­£ç¢ºã«å–å¾—ã§ãã‚‹ã€‚
    
    æ³¨æ„: ã“ã®ãƒ•ãƒƒã‚¯ã¯ deselect ãƒ•ã‚£ãƒ«ã‚¿é©ç”¨å¾Œã«å‘¼ã°ã‚Œã‚‹ãŸã‚ã€
    items ã«ã¯å®Ÿéš›ã«å®Ÿè¡Œã•ã‚Œã‚‹ãƒ†ã‚¹ãƒˆã®ã¿ãŒå«ã¾ã‚Œã‚‹ã€‚
    """
    import sys
    import re
    
    # --test-range ã‚ªãƒ—ã‚·ãƒ§ãƒ³ã«ã‚ˆã‚‹ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
    test_range = config.getoption("--test-range", None)
    if test_range:
        allowed_ids = _parse_test_range(test_range)
        selected = []
        deselected = []
        
        for item in items:
            # ãƒ†ã‚¹ãƒˆåã‹ã‚‰ TEST_XXXX ã®ç•ªå·ã‚’æŠ½å‡º
            match = re.search(r'TEST_(\d+)', item.name)
            if match:
                test_num = int(match.group(1))
                if test_num in allowed_ids:
                    selected.append(item)
                else:
                    deselected.append(item)
            else:
                # TEST_XXXX å½¢å¼ã§ãªã„ãƒ†ã‚¹ãƒˆã¯é™¤å¤–
                deselected.append(item)
        
        if deselected:
            config.hook.pytest_deselected(items=deselected)
        items[:] = selected
        
        SLog.info(LogCategory.CONFIG, LogEvent.UPDATE, {
            "range": test_range,
            "selected_count": len(selected)
        }, f"--test-range: {len(selected)}ä»¶ã®ãƒ†ã‚¹ãƒˆã‚’é¸æŠ")
    
    total = len(items)
    sys._pytest_total_tests = total
    sys._pytest_test_order = {}
    
    for i, item in enumerate(items, 1):
        # å„ãƒ†ã‚¹ãƒˆã«å®Ÿè¡Œé †ã‚’ä»˜ä¸
        item._test_progress_current = i
        item._test_progress_total = total
        # ãƒ†ã‚¹ãƒˆåã‹ã‚‰é †ç•ªã‚’å¼•ã‘ã‚‹ã‚ˆã†ã«ãƒãƒƒãƒ—ã‚‚ä½œæˆ
        sys._pytest_test_order[item.name] = i
    
    # Note: [PROGRESS] collected ã¯ pytest_collection_finish ã§å‡ºåŠ›


def pytest_collection_finish(session):
    """ãƒ†ã‚¹ãƒˆåé›†å®Œäº†å¾Œï¼ˆã™ã¹ã¦ã®ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°é©ç”¨å¾Œï¼‰ã«å‘¼ã°ã‚Œã‚‹"""
    import sys
    # session.items ã«ã¯æœ€çµ‚çš„ã«å®Ÿè¡Œã•ã‚Œã‚‹ãƒ†ã‚¹ãƒˆã®ã¿ãŒå«ã¾ã‚Œã‚‹
    total = len(session.items)
    sys._pytest_total_tests = total
    
    # ã‚»ãƒƒã‚·ãƒ§ãƒ³çµ±è¨ˆã‚’æ›´æ–°
    if hasattr(sys, '_pytest_session_stats'):
        sys._pytest_session_stats["total"] = total
    
    # å„ãƒ†ã‚¹ãƒˆã«æ­£ã—ã„é †ç•ªã‚’å†è¨­å®š
    for i, item in enumerate(session.items, 1):
        item._test_progress_current = i
        item._test_progress_total = total
        sys._pytest_test_order[item.name] = i
    
    # ãƒ†ã‚¹ãƒˆç·æ•°ã‚’ãƒ­ã‚°å‡ºåŠ›ï¼ˆè§£æç”¨ï¼‰
    SLog.log(LogCategory.SESSION, LogEvent.COLLECT, {
        "total_tests": total,
        "test_ids": [item.name for item in session.items]
    }, f"ãƒ†ã‚¹ãƒˆåé›†å®Œäº†: {total}ä»¶ã®ãƒ†ã‚¹ãƒˆã‚’å®Ÿè¡Œã—ã¾ã™")


def pytest_runtest_setup(item):
    """å„ãƒ†ã‚¹ãƒˆå®Ÿè¡Œå‰ã«ç¾åœ¨ã®ãƒ†ã‚¹ãƒˆã‚¢ã‚¤ãƒ†ãƒ ã‚’ä¿å­˜"""
    import sys
    sys._pytest_current_item = item


def pytest_runtest_logreport(report):
    """å„ãƒ†ã‚¹ãƒˆå®Ÿè¡Œå¾Œã«çµæœã‚’è¨˜éŒ²"""
    import sys
    
    # call ãƒ•ã‚§ãƒ¼ã‚ºï¼ˆå®Ÿéš›ã®ãƒ†ã‚¹ãƒˆå®Ÿè¡Œï¼‰ã®çµæœã®ã¿ã‚’è¨˜éŒ²
    if report.when == "call":
        if hasattr(sys, '_pytest_session_stats'):
            stats = sys._pytest_session_stats
            
            if report.passed:
                stats["passed"] += 1
            elif report.failed:
                stats["failed"] += 1
            elif report.skipped:
                stats["skipped"] += 1


def pytest_sessionstart(session):
    """ãƒ†ã‚¹ãƒˆã‚»ãƒƒã‚·ãƒ§ãƒ³é–‹å§‹æ™‚ã®å‡¦ç†"""
    from pathlib import Path
    from datetime import datetime
    import sys
    
    # ã‚³ãƒãƒ³ãƒ‰å®Ÿè¡Œã”ã¨ã®ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ã‚’ç”Ÿæˆ
    run_timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    
    # 1å›ã®ã‚³ãƒãƒ³ãƒ‰å®Ÿè¡Œã”ã¨ã®ãƒ•ã‚©ãƒ«ãƒ€ã‚’ä½œæˆ
    # smartestiroid_logs/run_YYYYMMDD_HHMMSS/
    base_log_dir = Path(os.getcwd()) / "smartestiroid_logs"
    run_log_dir = base_log_dir / f"run_{run_timestamp}"
    run_log_dir.mkdir(parents=True, exist_ok=True)
    
    # ã‚»ãƒƒã‚·ãƒ§ãƒ³å…¨ä½“ã§å…±æœ‰ã™ã‚‹ãŸã‚ã«ã‚°ãƒ­ãƒ¼ãƒãƒ«å¤‰æ•°ã«ä¿å­˜
    sys._pytest_run_log_dir = run_log_dir
    
    # ã‚»ãƒƒã‚·ãƒ§ãƒ³çµ±è¨ˆã‚’åˆæœŸåŒ–
    sys._pytest_session_stats = {
        "total": 0,
        "passed": 0,
        "failed": 0,
        "skipped": 0,
        "start_time": time.time()
    }
    
    # ãƒ­ã‚°ã‚’åˆæœŸåŒ–ï¼ˆå®Ÿè¡Œã”ã¨ã®ãƒ•ã‚©ãƒ«ãƒ€å†…ã«ä¿å­˜ï¼‰
    SLog.init(test_id="session", output_dir=run_log_dir)
    SLog.log(LogCategory.SESSION, LogEvent.START, {
        "timestamp": run_timestamp,
        "log_dir": str(run_log_dir)
    }, f"ãƒ†ã‚¹ãƒˆã‚»ãƒƒã‚·ãƒ§ãƒ³é–‹å§‹ (ãƒ­ã‚°: {run_log_dir.name})")


def pytest_sessionfinish(session, exitstatus):
    """ãƒ†ã‚¹ãƒˆã‚»ãƒƒã‚·ãƒ§ãƒ³çµ‚äº†æ™‚ã«å…¨ä½“ã®èª²é‡‘æƒ…å ±ã‚’Allureãƒ¬ãƒãƒ¼ãƒˆã«æ›¸ãè¾¼ã‚€"""
    import sys
    
    # ãƒ†ã‚¹ãƒˆçµæœã‚µãƒãƒªãƒ¼ã‚’ãƒ­ã‚°å‡ºåŠ›
    if hasattr(sys, '_pytest_session_stats'):
        stats = sys._pytest_session_stats
        elapsed_time = time.time() - stats.get("start_time", 0)
        
        # SESSION/SUMMARYã‚¤ãƒ™ãƒ³ãƒˆã§çµ±è¨ˆã‚’å‡ºåŠ›ï¼ˆè§£æã—ã‚„ã™ã„å½¢å¼ï¼‰
        SLog.log(LogCategory.SESSION, LogEvent.SUMMARY, {
            "total_tests": stats.get("total", 0),
            "passed": stats.get("passed", 0),
            "failed": stats.get("failed", 0),
            "skipped": stats.get("skipped", 0),
            "elapsed_seconds": round(elapsed_time, 2),
            "exit_status": exitstatus
        }, f"ãƒ†ã‚¹ãƒˆçµæœã‚µãƒãƒªãƒ¼: ç·æ•°={stats.get('total', 0)}, æˆåŠŸ={stats.get('passed', 0)}, å¤±æ•—={stats.get('failed', 0)}, ã‚¹ã‚­ãƒƒãƒ—={stats.get('skipped', 0)}")
    
    SLog.info(LogCategory.TOKEN, LogEvent.START, {"event": "generating_report"}, "Generating Global Token Usage Report")
    
    # ãƒ†ã‚¹ãƒˆçµ‚äº†æ™‚ã®ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ã‚’ãƒ­ã‚°å‡ºåŠ›
    exit_status_map = {0: "PASSED", 1: "FAILED", 2: "INTERRUPTED", 5: "NO_TESTS"}
    status_str = exit_status_map.get(exitstatus, f"UNKNOWN({exitstatus})")
    SLog.log(LogCategory.SESSION, LogEvent.END, {"exit_status": exitstatus, "status": status_str}, f"ãƒ†ã‚¹ãƒˆã‚»ãƒƒã‚·ãƒ§ãƒ³çµ‚äº†: {status_str}")
    
    # ã‚°ãƒ­ãƒ¼ãƒãƒ«çµ±è¨ˆã®ãƒ†ã‚­ã‚¹ãƒˆã¯ã‚³ãƒ³ã‚½ãƒ¼ãƒ«ã«å‡ºåŠ›ã—ãªã„
    global_summary_text = TiktokenCountCallback.format_global_summary()
    
    # Allureãƒ¬ãƒãƒ¼ãƒˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®ç¢ºèª
    allure_results_dir = session.config.option.allure_report_dir
    if not allure_results_dir:
        # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã®allure-resultsãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ä½¿ç”¨
        allure_results_dir = "allure-results"
    
    if not os.path.exists(allure_results_dir):
        os.makedirs(allure_results_dir)
    
    # ã‚°ãƒ­ãƒ¼ãƒãƒ«ã‚µãƒãƒªãƒ¼ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
    global_summary = TiktokenCountCallback.get_global_summary()
    session_history = TiktokenCountCallback.get_global_history()
    
    # CSVãƒ•ã‚¡ã‚¤ãƒ«åã‚’ç”Ÿæˆï¼ˆã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ä»˜ãï¼‰
    csv_filename = f"token-usage-{time.strftime('%Y%m%d%H%M%S')}.csv"
    csv_file = os.path.join(allure_results_dir, csv_filename)
    
    # CSVãƒ•ã‚¡ã‚¤ãƒ«ã«ã‚»ãƒƒã‚·ãƒ§ãƒ³è©³ç´°ã‚’ä¿å­˜
    import csv
    with open(csv_file, "w", encoding="utf-8", newline='') as f:
        writer = csv.writer(f)
        # ãƒ˜ãƒƒãƒ€ãƒ¼è¡Œ
        writer.writerow([
            "Session Label",
            "Timestamp",
            "Total Invocations",
            "Total Tokens",
            "Input Tokens",
            "Output Tokens",
            "Cached Tokens",
            "Total Cost (USD)"
        ])
        
        # å„ã‚»ãƒƒã‚·ãƒ§ãƒ³ã®è©³ç´°
        for session in session_history:
            writer.writerow([
                session.get('session_label', ''),
                session.get('timestamp', ''),
                session.get('total_invocations', 0),
                session.get('total_tokens', 0),
                session.get('total_input_tokens', 0),
                session.get('total_output_tokens', 0),
                session.get('total_cached_tokens', 0),
                f"{session.get('total_cost_usd', 0.0):.6f}"
            ])
        
        # ã‚µãƒãƒªãƒ¼è¡Œï¼ˆç©ºè¡Œã®å¾Œã«è¿½åŠ ï¼‰
        writer.writerow([])
        writer.writerow([
            "TOTAL",
            "",
            global_summary.get('total_invocations', 0),
            global_summary.get('total_tokens', 0),
            global_summary.get('total_input_tokens', 0),
            global_summary.get('total_output_tokens', 0),
            global_summary.get('total_cached_tokens', 0),
            f"{global_summary.get('total_cost_usd', 0.0):.6f}"
        ])
    
    SLog.info(LogCategory.TOKEN, LogEvent.COMPLETE, {"file": csv_file}, f"Token usage CSV written to {csv_file}")
    
    # environment.propertiesã®å…ˆé ­ã«èª²é‡‘æƒ…å ±ã‚’è¿½åŠ 
    env_file = os.path.join(allure_results_dir, "environment.properties")
    
    # æ—¢å­˜ã®å†…å®¹ã‚’èª­ã¿è¾¼ã‚€
    existing_content = ""
    if os.path.exists(env_file):
        with open(env_file, "r", encoding="utf-8") as f:
            existing_content = f.read()
    
    # æ–°ã—ã„å†…å®¹ã‚’ä½œæˆï¼ˆå…ˆé ­ã«èª²é‡‘æƒ…å ±ï¼‰
    total_invocations = global_summary.get('total_invocations', 0)
    avg_cost = global_summary.get('total_cost_usd', 0.0) / total_invocations if total_invocations > 0 else 0.0
    
    with open(env_file, "w", encoding="utf-8") as f:
        # LLMèª²é‡‘æƒ…å ±ã‚’å…ˆé ­ã«æ›¸ãè¾¼ã¿
        f.write(f"LLM_totalCostUSD={global_summary.get('total_cost_usd', 0.0):.6f}\n")
        f.write(f"LLM_totalTokens={global_summary.get('total_tokens', 0)}\n")
        f.write(f"LLM_totalInvocations={global_summary.get('total_invocations', 0)}\n")
        f.write(f"LLM_avgCostPerCall={avg_cost:.6f}\n")
        f.write(f"BillingDashboardFile={csv_filename}\n")
        f.write("\n")
        
        # æ—¢å­˜ã®å†…å®¹ã‚’è¿½åŠ 
        f.write(existing_content)
    
    SLog.info(LogCategory.TOKEN, LogEvent.COMPLETE, {"file": env_file}, f"Global token usage written to {env_file}")
    
    # ãƒ­ã‚°è§£æãƒ•ã‚¡ã‚¤ãƒ«ã‚’è‡ªå‹•ç”Ÿæˆï¼ˆLLMè§£æç”¨ï¼‰
    _generate_log_analysis()
    
    # ãƒ­ã‚°ã‚’é–‰ã˜ã‚‹
    SLog.close()


def _generate_log_analysis():
    """ãƒ†ã‚¹ãƒˆçµ‚äº†æ™‚ã«ãƒ­ã‚°è§£æãƒ•ã‚¡ã‚¤ãƒ«ã‚’è‡ªå‹•ç”Ÿæˆ"""
    from .utils.log_analyzer import LogAnalyzer
    from .utils.failure_report_generator import FailureReportGenerator
    
    log_file = SLog.get_log_file()
    if log_file and log_file.exists():
        try:
            analyzer = LogAnalyzer(log_file)
            
            # LLMè§£æç”¨ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‡ºåŠ›
            analyzer.export_for_llm_analysis()
            
            # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‡ºåŠ›
            analyzer.export_prompts()
            
            SLog.info(
                LogCategory.SESSION, 
                LogEvent.COMPLETE, 
                {"analysis_file": str(log_file.parent / f"{log_file.stem}_analysis.txt")},
                f"ãƒ­ã‚°è§£æãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç”Ÿæˆã—ã¾ã—ãŸ"
            )
        except Exception as e:
            SLog.warn(
                LogCategory.SESSION,
                LogEvent.FAIL,
                {"error": str(e)},
                f"ãƒ­ã‚°è§£æãƒ•ã‚¡ã‚¤ãƒ«ã®ç”Ÿæˆã«å¤±æ•—: {e}"
            )
        
        # å¤±æ•—ãƒ¬ãƒãƒ¼ãƒˆã‚’ç”Ÿæˆ
        try:
            log_dir = log_file.parent
            generator = FailureReportGenerator(log_dir=log_dir)
            report_path = generator.generate_report()
            SLog.info(
                LogCategory.SESSION,
                LogEvent.COMPLETE,
                {"report_file": str(report_path)},
                f"å¤±æ•—ãƒ¬ãƒãƒ¼ãƒˆã‚’ç”Ÿæˆã—ã¾ã—ãŸ: {report_path.name}"
            )
        except Exception as e:
            SLog.warn(
                LogCategory.SESSION,
                LogEvent.FAIL,
                {"error": str(e)},
                f"å¤±æ•—ãƒ¬ãƒãƒ¼ãƒˆã®ç”Ÿæˆã«å¤±æ•—: {e}"
            )


async def evaluate_task_result(
    task_input: str, response: str, executed_steps: list = None, replanner_judgment: str = None, state_analysis: str = None, token_callback=None
) -> str:
    """ã‚¿ã‚¹ã‚¯çµæœã‚’æ§‹é€ åŒ–è©•ä¾¡ã— RESULT_PASS / RESULT_SKIP / RESULT_FAIL ã‚’å³å¯†è¿”å´ã™ã‚‹
    
    Args:
        task_input: å…ƒã®ã‚¿ã‚¹ã‚¯æŒ‡ç¤º
        response: æœ€çµ‚å¿œç­”
        executed_steps: å®Ÿè¡Œã•ã‚ŒãŸã‚¹ãƒ†ãƒƒãƒ—å±¥æ­´
        replanner_judgment: ãƒªãƒ—ãƒ©ãƒ³ãƒŠãƒ¼ãŒRESPONSEã¨åˆ¤æ–­ã—ãŸã¨ãã®å†…å®¹ï¼ˆstatus, reasonï¼‰
        state_analysis: ãƒªãƒ—ãƒ©ãƒ³ãƒŠãƒ¼ã«ã‚ˆã‚‹çŠ¶æ…‹åˆ†æçµæœ
        token_callback: ãƒˆãƒ¼ã‚¯ãƒ³ã‚«ã‚¦ãƒ³ã‚¿ãƒ¼ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯
    """
    # ä½¿ç”¨ãƒ¢ãƒ‡ãƒ«ã®æ±ºå®šï¼ˆå‹•çš„ã«å–å¾—ï¼‰
    model = cfg.evaluation_model

    # ãƒ¢ãƒ‡ãƒ«ã¯ç¾çŠ¶å›ºå®šï¼ˆç°¡ç´ åŒ–ï¼‰
    callbacks = [token_callback] if token_callback else []
    llm = ChatOpenAI(
        model=model,
        temperature=0,
        timeout=OPENAI_TIMEOUT,
        max_retries=OPENAI_MAX_RETRIES,
        callbacks=callbacks if callbacks else None
    )
    SLog.info(LogCategory.LLM, LogEvent.START, {"model": model, "purpose": "evaluation"}, f"è©•ä¾¡ç”¨ãƒ¢ãƒ‡ãƒ«: {model}")

    # å®Ÿè¡Œã‚¹ãƒ†ãƒƒãƒ—å±¥æ­´ã®æ–‡å­—åˆ—åŒ–
    steps_summary = ""
    if executed_steps:
        for i, step_info in enumerate(executed_steps, 1):
            success_mark = "âœ“" if step_info["success"] else "âœ—"
            steps_summary += f"{i}. {success_mark} {step_info['step']}\n"

    evaluation_prompt = f"""
ã‚ãªãŸã¯ãƒ†ã‚¹ãƒˆçµæœåˆ¤å®šã®ã‚¨ã‚­ã‚¹ãƒ‘ãƒ¼ãƒˆã§ã™ã€‚ä»¥ä¸‹ã‚’å³å¯†ã«æ¤œè¨¼ã— JSON ã®ã¿ã§è¿”ç­”ã—ã¦ãã ã•ã„ã€‚

# å…ƒã‚¿ã‚¹ã‚¯æŒ‡ç¤º:
{task_input}

# å®Ÿè¡Œã‚¹ãƒ†ãƒƒãƒ—å±¥æ­´:
{steps_summary or '(ãªã—)'}

# ç¾åœ¨ã®ç”»é¢çŠ¶æ…‹åˆ†æçµæœ:
{state_analysis}

# ãƒªãƒ—ãƒ©ãƒ³ãƒŠãƒ¼ã®åˆ¤æ–­çµæœ:
{replanner_judgment}

# æœ€çµ‚å¿œç­”:
{response}

# åˆ¤å®šè¦å‰‡:
1. {RESULT_PASS} ã®æ¡ä»¶:
    - æŒ‡ç¤ºæ‰‹é †ã‚’éä¸è¶³ãªãå®Ÿè¡Œ
    - ä¸è¦/é€¸è„±ã‚¹ãƒ†ãƒƒãƒ—ãªã—
    - å¿œç­”å†…ã«æœŸå¾…åŸºæº–ã¸ç›´æ¥å¯¾å¿œã™ã‚‹å…·ä½“çš„æ ¹æ‹ ï¼ˆè¦ç´ ID / text / ç”»åƒèª¬æ˜ / æ“ä½œçµæœï¼‰ãŒå­˜åœ¨
    - ç”»åƒè©•ä¾¡ãŒå¿…è¦ãªã‚±ãƒ¼ã‚¹ã§ã¯ãã®æ ¹æ‹ ã‚’è¨€åŠ
    - ä»¥ä¸‹ã®å¯¾å¿œã¯ã€æœ¬ã‚¿ã‚¹ã‚¯ã®è©•ä¾¡å¯¾è±¡å¤–ã¨ã—ã€ä¸è¦ã‚ã‚‹ã„ã¯é€¸è„±ã‚¹ãƒ†ãƒƒãƒ—ã¨ã—ã¦æ‰±ã‚ãªã„ï¼šãƒ—ãƒ©ã‚¤ãƒã‚·ãƒ¼ãƒãƒªã‚·ãƒ¼ã€ãƒ‡ã‚£ã‚¹ã‚¯ãƒ¬ãƒ¼ãƒãƒ¼ã€åˆæœŸè¨­å®šãƒ€ã‚¤ã‚¢ãƒ­ã‚°ã€åºƒå‘Šãƒ€ã‚¤ã‚¢ãƒ­ã‚° ãªã©

2. {RESULT_SKIP} ã®æ¡ä»¶:
    - æ ¹æ‹ ãŒæ›–æ˜§ / åè¨¼ä¸èƒ½ / ä¸»è¦³çš„
    - å¿…è¦æ‰‹é †ä¸è¶³ or ä½™è¨ˆãªæ“ä½œã‚ã‚Š
    - ãƒ­ã‚±ãƒ¼ã‚¿ / ç”»åƒç¢ºèªãŒå¿…è¦ãªã®ã«ä¸ååˆ†
    - ã‚¨ãƒ©ãƒ¼ / ä¸æ•´åˆ / åˆ¤å®šå›°é›£

# å‡ºåŠ›ä»•æ§˜:
å³å¯†JSON
"""
    # LLMãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ãƒ­ã‚°å‡ºåŠ›
    SLog.log(LogCategory.LLM, LogEvent.START, {
        "method": "evaluate_task_result",
        "prompt": evaluation_prompt
    }, "LLMãƒ—ãƒ­ãƒ³ãƒ—ãƒˆé€ä¿¡: evaluate_task_result", attach_to_allure=True)

    try:
        messages = [
            SystemMessage(content="ã‚ãªãŸã¯æ­£ç¢ºãªãƒ†ã‚¹ãƒˆçµæœåˆ¤å®šã‚’è¡Œã†ã‚¨ã‚­ã‚¹ãƒ‘ãƒ¼ãƒˆã§ã™ã€‚JSONã®ã¿è¿”ç­”ã€‚"),
            HumanMessage(content=evaluation_prompt),
        ]
        structured_llm = llm.with_structured_output(EvaluationResult)
        
        # track_query()ã§ã‚¯ã‚¨ãƒªã”ã¨ã®ãƒˆãƒ¼ã‚¯ãƒ³ä½¿ç”¨é‡ã‚’è¨˜éŒ²
        with token_callback.track_query():
            eval_struct: EvaluationResult = await structured_llm.ainvoke(messages)

        status = eval_struct.status
        reason = eval_struct.reason.strip()

        # LLMãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚’ãƒ­ã‚°å‡ºåŠ›
        SLog.log(LogCategory.TEST, LogEvent.COMPLETE, {
            "status": status,
            "reason": reason
        }, f"è©•ä¾¡å®Œäº†: {status}")
        SLog.attach_text(eval_struct.to_allure_text(), "ğŸ’¡ LLM Response: Task Evaluation")

        return f"{status}\nåˆ¤å®šç†ç”±:\n{reason}"
    except Exception as e:
        err_type = type(e).__name__
        SLog.error(LogCategory.LLM, LogEvent.FAIL, {"error_type": err_type, "error": str(e)}, f"[evaluate_task_result] Exception: {err_type}: {e}")
        SLog.attach_text(
            f"Exception Type: {err_type}\nLocation: evaluate_task_result\nMessage: {e}",
            "âŒ evaluate_task_result Exception"
        )
        log_openai_error_to_allure(
            error_type=err_type,
            location="evaluate_task_result",
            model=model,
            error=e
        )
        return f"{RESULT_SKIP}\nåˆ¤å®šç†ç”±: è©•ä¾¡ä¸­ã‚¨ãƒ©ãƒ¼ ({err_type})"


# --- ãƒ˜ãƒ«ãƒ‘ãƒ¼é–¢æ•° ---
# (generate_screen_info ã¯ utils.screen_helper ã«ç§»å‹•)


# --- ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼é–¢æ•°ã®å®šç¾© ---
async def agent_session(no_reset: bool = True, dont_stop_app_on_reset: bool = False, knowhow: str = KNOWHOW_INFO):
    """MCPã‚»ãƒƒã‚·ãƒ§ãƒ³å†…ã§graphã‚’ä½œæˆã—ã€ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚’ç¶­æŒã—ãªãŒã‚‰yieldã™ã‚‹

    Args:
        no_reset: appium:noResetã®è¨­å®šå€¤ã€‚Trueï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆï¼‰ã¯ãƒªã‚»ãƒƒãƒˆãªã—ã€Falseã¯ãƒªã‚»ãƒƒãƒˆã‚ã‚Šã€‚
        knowhow: ãƒã‚¦ãƒã‚¦æƒ…å ±ã€‚ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã¯KNOWHOW_INFOã€ã‚«ã‚¹ã‚¿ãƒ knowhowã‚’æ¸¡ã™ã“ã¨ã‚‚å¯èƒ½ã€‚
    """
    
    options = UiAutomator2Options()
    capabilities = {}

    try:
        with open(capabilities_path, "r") as f:
            capabilities = json.load(f)

            # ä»»æ„ã®è¿½åŠ è¨­å®š
            capabilities.update({
                "appium:noReset": no_reset, # noResetãŒTrueãªã‚‰ã‚¢ãƒ—ãƒªã‚’ãƒªã‚»ãƒƒãƒˆã—ãªã„
                "appium:appWaitActivity": "*", # ã™ã¹ã¦ã®ã‚¢ã‚¯ãƒ†ã‚£ãƒ“ãƒ†ã‚£ã‚’å¾…æ©Ÿ
                "appium:autoGrantPermissions": True, # æ¨©é™ã‚’è‡ªå‹•ä»˜ä¸
                "appium:dontStopAppOnReset": dont_stop_app_on_reset, # ã‚»ãƒƒã‚·ãƒ§ãƒ³ãƒªã‚»ãƒƒãƒˆæ™‚ã«ã‚¢ãƒ—ãƒªã‚’åœæ­¢ã—ãªã„
                "appium:adbExecTimeout": 60000,
            })

            # Apply all capabilities from the loaded dictionary
            for key, value in capabilities.items():
                # Set each capability dynamically
                options.set_capability(key, value)
    except FileNotFoundError:
        SLog.error(LogCategory.CONFIG, LogEvent.FAIL, {"path": capabilities_path}, f"è­¦å‘Š: {capabilities_path} ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚")
        raise

    except json.JSONDecodeError:
        SLog.error(LogCategory.CONFIG, LogEvent.FAIL, {"path": capabilities_path}, f"è­¦å‘Š: {capabilities_path} ã®JSONå½¢å¼ãŒç„¡åŠ¹ã§ã™ã€‚")
        raise

    

    try:
        async with appium_driver(options) as driver:
            # æœ€åˆã®ã‚»ãƒƒã‚·ãƒ§ãƒ³é–‹å§‹æ™‚ã«ãƒ‡ãƒã‚¤ã‚¹æƒ…å ±ã‚’å–å¾—ã—ã¦æ›¸ãè¾¼ã‚€
            await write_device_info_once(
                driver=driver,
                capabilities_path=capabilities_path,
                appium_tools_func=appium_tools
            )

            # å¿…è¦ãªãƒ„ãƒ¼ãƒ«ã‚’å–å¾—ï¼ˆãƒªã‚¹ãƒˆã‹ã‚‰åå‰ã§æ¤œç´¢ï¼‰
            tools_list = appium_tools()
            tools_dict = {tool.name: tool for tool in tools_list}
            screenshot_tool = tools_dict.get("take_screenshot")
            get_page_source_tool = tools_dict.get("get_page_source")
            activate_app = tools_dict.get("activate_app")
            terminate_app = tools_dict.get("terminate_app")
            
            # appPackageæƒ…å ±ã‚’knowhowã«è¿½åŠ ï¼ˆLLMãŒãƒ†ã‚¹ãƒˆå¯¾è±¡ã‚¢ãƒ—ãƒªã‚’èªè­˜ã§ãã‚‹ã‚ˆã†ã«ã™ã‚‹ï¼‰
            app_package = capabilities.get("appium:appPackage")
            if app_package:
                app_package_info = f"""
ãƒ†ã‚¹ãƒˆå¯¾è±¡ã‚¢ãƒ—ãƒªæƒ…å ±:
* ãƒ†ã‚¹ãƒˆå¯¾è±¡ã‚¢ãƒ—ãƒªã®ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ID: {app_package}
* activate_app ã‚„ terminate_app ã‚’ä½¿ç”¨ã™ã‚‹éš›ã¯ã€ã“ã®ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸IDã‚’ä½¿ç”¨ã—ã¦ãã ã•ã„
* åˆ¥ã®ã‚¢ãƒ—ãƒªã‚’èµ·å‹•ã™ã‚‹å¿…è¦ãŒã‚ã‚‹å ´åˆã‚’é™¤ãã€ã“ã®ã‚¢ãƒ—ãƒªã‚’æ“ä½œã—ã¦ãã ã•ã„
"""
                knowhow = app_package_info + "\n" + knowhow
                SLog.info(LogCategory.CONFIG, LogEvent.UPDATE, {"app_package": app_package}, f"ãƒ†ã‚¹ãƒˆå¯¾è±¡ã‚¢ãƒ—ãƒª: {app_package} (knowhowã«è¿½åŠ æ¸ˆã¿)")
            
            # noReset=True ã®å ´åˆã€appPackageã§æŒ‡å®šã•ã‚ŒãŸã‚¢ãƒ—ãƒªã‚’å¼·åˆ¶èµ·å‹•
            if no_reset:
                if app_package:
                    SLog.info(LogCategory.SESSION, LogEvent.START, {"app_package": app_package, "no_reset": True}, f"noReset=True: ã‚¢ãƒ—ãƒªã‚’å¼·åˆ¶èµ·å‹•ã—ã¾ã™ (appPackage={app_package})")
                    try:
                        activate_result = await activate_app.ainvoke({"app_id": app_package})
                        SLog.debug(LogCategory.SESSION, LogEvent.COMPLETE, {"result": str(activate_result)}, None)
                        SLog.info(LogCategory.SESSION, LogEvent.UPDATE, {"wait_seconds": 3}, "ã‚¢ãƒ—ãƒªèµ·å‹•å¾…æ©Ÿä¸­... (3ç§’)")
                        await asyncio.sleep(3)
                    except Exception as e:
                        SLog.warn(LogCategory.SESSION, LogEvent.FAIL, {"error": str(e)}, f"appium_activate_appå®Ÿè¡Œã‚¨ãƒ©ãƒ¼: {e}")
                else:
                    SLog.warn(LogCategory.SESSION, LogEvent.SKIP, {"reason": "no_app_package"}, "appPackageãŒæŒ‡å®šã•ã‚Œã¦ã„ãªã„ãŸã‚ã€ã‚¢ãƒ—ãƒªèµ·å‹•ã‚’ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™")
            else:
                # noReset=False ã®å ´åˆã¯é€šå¸¸é€šã‚Šå¾…æ©Ÿã®ã¿
                SLog.info(LogCategory.SESSION, LogEvent.UPDATE, {"wait_seconds": 3}, "ã‚¢ãƒ—ãƒªèµ·å‹•å¾…æ©Ÿä¸­... (3ç§’)")
                await asyncio.sleep(3)

            # ç’°å¢ƒå¤‰æ•°ã§ãƒ¢ãƒ‡ãƒ«é¸æŠï¼ˆå‹•çš„ã«å–å¾—ï¼‰
            SLog.info(LogCategory.CONFIG, LogEvent.UPDATE, {"model": cfg.execution_model}, f"ä½¿ç”¨ãƒ¢ãƒ‡ãƒ«: {cfg.execution_model}")

            # ãƒˆãƒ¼ã‚¯ãƒ³ã‚«ã‚¦ãƒ³ã‚¿ãƒ¼ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯ã‚’ä½œæˆ
            token_callback = TiktokenCountCallback(model=cfg.execution_model)

            # ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚¨ã‚°ã‚¼ã‚­ãƒ¥ãƒ¼ã‚¿ãƒ¼ã‚’ä½œæˆï¼ˆã‚«ã‚¹ã‚¿ãƒ knowhowã‚’ä½¿ç”¨ï¼‰
            llm = ChatOpenAI(
                model=cfg.execution_model,
                temperature=0,
                timeout=OPENAI_TIMEOUT,
                max_retries=OPENAI_MAX_RETRIES,
                callbacks=[token_callback]
            )
            prompt = f"""
ã‚ãªãŸã¯è¦ªåˆ‡ãªAndroidã‚¢ãƒ—ãƒªã‚’ãƒ„ãƒ¼ãƒ«ã§è‡ªå‹•æ“ä½œã™ã‚‹ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚ä¸ãˆã‚‰ã‚ŒãŸã‚¿ã‚¹ã‚¯ã‚’æ­£ç¢ºã«å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚

é‡è¦ãªå‰ææ¡ä»¶:
- äº‹å‰ã« appium ã¨ã¯æ¥ç¶šã•ã‚Œã¦ã„ã¾ã™

ã€ãƒ„ãƒ¼ãƒ«å‘¼ã³å‡ºã—ã®ãƒ«ãƒ¼ãƒ«ã€‘ï¼ˆå³å®ˆï¼‰:
- ãƒ„ãƒ¼ãƒ«ã‚’ä½¿ç”¨ã—ã¦ã‚¢ãƒ—ãƒªã‚’æ“ä½œã—ã¾ã™
- ãƒ„ãƒ¼ãƒ«ä»¥å¤–ã®æ–¹æ³•ã§ã‚¢ãƒ—ãƒªã‚’æ“ä½œã—ã¦ã¯ã„ã‘ã¾ã›ã‚“

ã€é‡è¦ã€‘ãƒ„ãƒ¼ãƒ«å‘¼ã³å‡ºã—ã®å³æ ¼ãƒ«ãƒ¼ãƒ«:
- ãƒ„ãƒ¼ãƒ«ã¯å¿…ãš1ã¤ãšã¤é †ç•ªã«å‘¼ã³å‡ºã™ã“ã¨ï¼ˆä¸¦åˆ—å‘¼ã³å‡ºã—ç¦æ­¢ï¼‰
- 1ã¤ã®ãƒ„ãƒ¼ãƒ«ã®çµæœã‚’ç¢ºèªã—ã¦ã‹ã‚‰æ¬¡ã®ãƒ„ãƒ¼ãƒ«ã‚’å‘¼ã³å‡ºã™ã“ã¨
- ä¾‹: send_keys â†’ çµæœç¢ºèª â†’ press_keycode ã®é †ã§å®Ÿè¡Œ

ã€ãƒ†ã‚­ã‚¹ãƒˆå…¥åŠ›ã®ãƒ«ãƒ¼ãƒ«ã€‘ï¼ˆå³å®ˆï¼‰:
- ãƒ†ã‚­ã‚¹ãƒˆå…¥åŠ›ã«ã¯å¿…ãš send_keys ã‚’ä½¿ç”¨ã™ã‚‹ã“ã¨
- press_keycode ã§1æ–‡å­—ãšã¤å…¥åŠ›ã—ã¦ã¯ã„ã‘ãªã„ï¼ˆåŠ¹ç‡ãŒæ‚ªãã€ã‚­ãƒ¼ã‚³ãƒ¼ãƒ‰å¤‰æ›ã‚¨ãƒ©ãƒ¼ãŒèµ·ãã‚„ã™ã„ï¼‰
- press_keycode ã¯ç‰¹æ®Šã‚­ãƒ¼ã«ã®ã¿ä½¿ç”¨: Enter(66), Back(4), Home(3), Delete(67) ãªã©
- æ­£ã—ã„ä¾‹: send_keys ã§ "yahoo.co.jp" ã‚’å…¥åŠ› â†’ press_keycode 66 ã§ç¢ºå®š
- èª¤ã£ãŸä¾‹: press_keycode ã§ 'y','a','h','o','o'... ã¨1æ–‡å­—ãšã¤å…¥åŠ›ï¼ˆç¦æ­¢ï¼‰

ãƒ­ã‚±ãƒ¼ã‚¿ãƒ¼æˆ¦ç•¥ã®åˆ¶ç´„ (å¿…ãšå®ˆã‚‹ã“ã¨)
* Androidã§ã¯ accessibility_id ã¯ä½¿ç”¨ç¦æ­¢
* è¦ç´ ã‚’æŒ‡å®šã™ã‚‹éš›ã¯å¿…ãš 'id' (resource-id), 'xpath', ã¾ãŸã¯ 'uiautomator' ã‚’ä½¿ç”¨ã›ã‚ˆ
* ä¾‹: {{'by': 'id', 'value': 'com.android.chrome:id/menu_button'}}
* ä¾‹: {{'by': 'xpath', 'value': '//android.widget.Button[@content-desc="More options"]'}}

ã€ãƒ‰ãƒ¡ã‚¤ãƒ³å›ºæœ‰ãƒ«ãƒ¼ãƒ«ã€‘
{knowhow}


"""

            agent_executor = create_agent(llm, appium_tools(), system_prompt=prompt)
            SLog.info(LogCategory.CONFIG, LogEvent.UPDATE, {"model": cfg.execution_model, "purpose": "agent_executor"}, f"Agent Executorç”¨ãƒ¢ãƒ‡ãƒ«: {cfg.execution_model}")

            planner = SimplePlanner(
                knowhow, 
                model_name=cfg.planner_model,
                token_callback=token_callback
            )

            # LLMã«æ¸¡ã•ã‚Œã‚‹knowhowæƒ…å ±ã‚’è¨˜éŒ²
            SLog.info(LogCategory.CONFIG, LogEvent.UPDATE, {"knowhow_length": len(knowhow)}, "LLMã«æ¸¡ã•ã‚Œã‚‹knowhowæƒ…å ±ã‚’è¨­å®š")
            SLog.debug(LogCategory.CONFIG, LogEvent.UPDATE, {"knowhow": knowhow}, None)

            # ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼é–¢æ•°ã‚’ä½œæˆï¼ˆã‚»ãƒƒã‚·ãƒ§ãƒ³å†…ã®ãƒ„ãƒ¼ãƒ«ã‚’ä½¿ç”¨ï¼‰
            max_replan_count = 20
            
            # evaluate_task_resultã‚’ãƒ©ãƒƒãƒ—ã—ã¦token_callbackã‚’æ¸¡ã™
            async def evaluate_with_token_callback(task_input, response, executed_steps, replanner_judgment=None, state_analysis=None):
                return await evaluate_task_result(task_input, response, executed_steps, replanner_judgment, state_analysis, token_callback)
            
            execute_step, plan_step, replan_step, should_end = (
                create_workflow_functions(
                    planner,
                    agent_executor,
                    screenshot_tool,
                    get_page_source_tool,
                    evaluate_with_token_callback,
                    max_replan_count,
                    knowhow,
                    token_callback,
                )
            )

            # ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã‚’æ§‹ç¯‰
            workflow = StateGraph(PlanExecute)
            workflow.add_node("planner", plan_step)
            workflow.add_node("agent", execute_step)
            workflow.add_node("replan", replan_step)
            workflow.add_edge(START, "planner")
            workflow.add_edge("planner", "agent")
            workflow.add_edge("agent", "replan")
            workflow.add_conditional_edges("replan", should_end, ["agent", END])
            graph = workflow.compile()

            # graphã¨past_stepsã‚’yieldã—ã¦ã€ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚’ç¶­æŒ    
            try:
                yield graph
            finally:
                # æœ€å°é™: ã‚»ãƒƒã‚·ãƒ§ãƒ³ã®ã‚°ãƒ­ãƒ¼ãƒãƒ«ä¿å­˜ã®ã¿ï¼ˆè¡¨ç¤ºã‚„æ·»ä»˜ã¯ã—ãªã„ï¼‰
                
                # ã‚°ãƒ­ãƒ¼ãƒãƒ«çµ±è¨ˆã«ä¿å­˜ï¼ˆãƒ†ã‚¹ãƒˆã‚±ãƒ¼ã‚¹IDã‚’ãƒ©ãƒ™ãƒ«ã¨ã—ã¦ä½¿ç”¨ï¼‰
                try:
                    # pytest ã®ç¾åœ¨ã®ãƒ†ã‚¹ãƒˆã‚¢ã‚¤ãƒ†ãƒ ã‹ã‚‰ãƒ†ã‚¹ãƒˆIDã‚’å–å¾—
                    import sys
                    test_id = "Unknown Test"
                    if hasattr(sys, '_pytest_current_item'):
                        test_id = sys._pytest_current_item.nodeid
                    
                    # ã‚°ãƒ­ãƒ¼ãƒãƒ«å±¥æ­´ã«ä¿å­˜
                    token_callback.save_session_to_global(test_id)
                except Exception:
                    pass
                
                # ã‚»ãƒƒã‚·ãƒ§ãƒ³çµ‚äº†å‰ã«ã‚¢ãƒ—ãƒªã‚’çµ‚äº†
                app_package = capabilities.get("appium:appPackage")
                dont_stop_app_on_reset = capabilities.get("appium:dontStopAppOnReset")
                if app_package and not dont_stop_app_on_reset:
                    SLog.info(LogCategory.SESSION, LogEvent.END, {"app_package": app_package}, f"ã‚»ãƒƒã‚·ãƒ§ãƒ³çµ‚äº†: ã‚¢ãƒ—ãƒªã‚’çµ‚äº†ã—ã¾ã™ (appPackage={app_package})")
                    try:
                        terminate_result = await terminate_app.ainvoke({"app_id": app_package})
                        SLog.debug(LogCategory.SESSION, LogEvent.COMPLETE, {"result": str(terminate_result)}, None)
                    except Exception as e:
                        error_msg = str(e)
                        # NoSuchDriverError ã‚„ session terminated ã‚¨ãƒ©ãƒ¼ã¯è­¦å‘Šãƒ¬ãƒ™ãƒ«ã§æ‰±ã†
                        if "NoSuchDriverError" in error_msg or "session is either terminated or not started" in error_msg or "session" in error_msg.lower():
                            SLog.warn(LogCategory.SESSION, LogEvent.SKIP, {"error": error_msg}, f"ã‚»ãƒƒã‚·ãƒ§ãƒ³ãŒæ—¢ã«çµ‚äº†ã—ã¦ã„ã¾ã™: {e}")
                        else:
                            SLog.warn(LogCategory.SESSION, LogEvent.FAIL, {"error": error_msg}, f"appium_terminate_appå®Ÿè¡Œã‚¨ãƒ©ãƒ¼: {e}")

    except Exception as e:
        error_msg = str(e)
        # NoSuchDriverError ã‚„ session terminated ã‚¨ãƒ©ãƒ¼ã¯æƒ…å ±ãƒ¬ãƒ™ãƒ«ã§æ‰±ã†
        if "NoSuchDriverError" in error_msg or "session is either terminated or not started" in error_msg:
            SLog.warn(LogCategory.SESSION, LogEvent.SKIP, {"error": error_msg}, f"agent_session: ã‚»ãƒƒã‚·ãƒ§ãƒ³ãŒæ—¢ã«çµ‚äº†ã—ã¦ã„ã¾ã™: {e}")
        else:
            SLog.error(LogCategory.SESSION, LogEvent.FAIL, {"error": error_msg}, f"agent_sessionã§ã‚¨ãƒ©ãƒ¼: {e}")
            raise e
    finally:
        SLog.info(LogCategory.SESSION, LogEvent.END, None, "ã‚»ãƒƒã‚·ãƒ§ãƒ³çµ‚äº†")


class SmartestiRoid:
    """ãƒ†ã‚¹ãƒˆç”¨ã®Plan-and-Executeã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚¯ãƒ©ã‚¹"""

    def __init__(self, agent_session, no_reset: bool = True, dont_stop_app_on_reset: bool = False, knowhow: str = KNOWHOW_INFO):
        self.agent_session = agent_session
        self.no_reset = no_reset
        self.dont_stop_app_on_reset = dont_stop_app_on_reset
        self.knowhow = knowhow  # ãƒã‚¦ãƒã‚¦æƒ…å ±ã‚’ä¿æŒ

    async def validate_task(
        self,
        steps: str,
        expected: str = "",
        knowhow: Optional[str] = None,
    ) -> str:
        """
        ã‚¿ã‚¹ã‚¯ã‚’å®Ÿè¡Œã—ã¦çµæœã‚’æ¤œè¨¼ã™ã‚‹
        
        Args:
            task: å®Ÿè¡Œã™ã‚‹ã‚¿ã‚¹ã‚¯
            ignore_case: å¤§æ–‡å­—å°æ–‡å­—ã‚’ç„¡è¦–ã™ã‚‹ã‹
            knowhow: ã‚«ã‚¹ã‚¿ãƒ knowhowæƒ…å ±ï¼ˆNoneã®å ´åˆã¯ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã®knowhowã‚’ä½¿ç”¨ï¼‰
        """
        config = {"recursion_limit": 50}

        # knowhowã®æ±ºå®š: ãƒ¡ã‚½ãƒƒãƒ‰å¼•æ•° > ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹å¤‰æ•° > ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ
        effective_knowhow = knowhow if knowhow is not None else self.knowhow

        # ã‚«ã‚¹ã‚¿ãƒ knowhowã‚’ä½¿ç”¨ã™ã‚‹å ´åˆã€æ–°ã—ã„ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚’ä½œæˆ
        async for graph in self.agent_session(self.no_reset, self.dont_stop_app_on_reset, effective_knowhow):
            # state["input"]ã«ã¯ç´”ç²‹ãªã‚¿ã‚¹ã‚¯ã®ã¿ã‚’æ¸¡ã™
            # knowhowã¯å„LLMï¼ˆSimplePlannerã€agent_executorï¼‰ãŒæ—¢ã«æŒã£ã¦ã„ã‚‹
            task = (
                f"ãƒ†ã‚¹ãƒˆå®Ÿæ–½æ‰‹é †:{steps}\n\n"
                f"ãƒ†ã‚¹ãƒˆåˆå¦åˆ¤å®šåŸºæº–:{expected}\n"
            )
            inputs = {"input": task}
            
            if knowhow is not None:
                SLog.info(LogCategory.CONFIG, LogEvent.UPDATE, {"custom_knowhow": True}, f"ã‚«ã‚¹ã‚¿ãƒ knowhowæƒ…å ±ã‚’ä½¿ç”¨: {knowhow[:100]}...")

            SLog.info(LogCategory.TEST, LogEvent.START, {"agent": "plan_and_execute"}, "Plan-and-Execute Agent é–‹å§‹")
            try:
                final_result = {"response": ""}
                async for event in graph.astream(inputs, config=config):
                    for k, v in event.items():
                        if k != "__end__":
                            SLog.debug(LogCategory.STEP, LogEvent.UPDATE, {"event": k, "value": str(v)[:200]}, None)
                            final_result = v

            except Exception as e:
                SLog.error(LogCategory.TEST, LogEvent.FAIL, {"error": str(e)}, f"å®Ÿè¡Œä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
                SLog.attach_text(
                    f"ãƒ†ã‚¹ãƒˆå®Ÿè¡Œä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ:\n{e}",
                    "âŒ Test Execution Error"
                )
                assert False, f"ãƒ†ã‚¹ãƒˆå®Ÿè¡Œä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}"
            finally:
                SLog.info(LogCategory.TEST, LogEvent.END, {"agent": "plan_and_execute"}, "Plan-and-Execute Agent çµ‚äº†")
            # async forãƒ«ãƒ¼ãƒ—ã¯ä¸€åº¦ã ã‘å®Ÿè¡Œã•ã‚Œã‚‹ã®ã§breakãŒä¸è¦

        # validation
        result_text = final_result.get("response", None)
        assert result_text is not None, "Agent did not return a final result."

        # RESULT_SKIPãŒå«ã¾ã‚Œã¦ã„ã‚‹å ´åˆã¯ã€pytestã§skipã™ã‚‹
        if RESULT_SKIP in result_text:
            SLog.log(LogCategory.TEST, LogEvent.SKIP, {"result": "SKIP"}, "â­ï¸ SKIP: ã“ã®ãƒ†ã‚¹ãƒˆã¯å‡ºåŠ›çµæœã®ç›®è¦–ç¢ºèªãŒå¿…è¦ã§ã™")
            pytest.skip("ã“ã®ãƒ†ã‚¹ãƒˆã¯å‡ºåŠ›çµæœã®ç›®è¦–ç¢ºèªãŒå¿…è¦ã§ã™")

        # RESULT_FAILãŒå«ã¾ã‚Œã¦ã„ã‚‹å ´åˆã¯ã€ãƒ†ã‚¹ãƒˆå¤±æ•—ã¨ã—ã¦å‡¦ç†
        if RESULT_FAIL in result_text:
            SLog.log(LogCategory.TEST, LogEvent.FAIL, {"result": "FAIL"}, "âŒ FAIL: ãƒ†ã‚¹ãƒˆãŒå¤±æ•—ã—ã¾ã—ãŸ")
            # è©³ç´°ã¯workflow.pyã§Allureã«æ·»ä»˜æ¸ˆã¿ãªã®ã§ã€ã“ã“ã§ã¯æ·»ä»˜ã—ãªã„
            pytest.fail(f"ãƒ†ã‚¹ãƒˆãŒå¤±æ•—ã—ã¾ã—ãŸ:\n{result_text}")

        # RESULT_PASSãŒå«ã¾ã‚Œã¦ã„ã‚‹ã‹ç¢ºèª
        if RESULT_PASS.lower() not in result_text.lower():
            SLog.log(LogCategory.TEST, LogEvent.FAIL, {"result": "FAIL"}, "âŒ FAIL: ãƒ†ã‚¹ãƒˆãŒå¤±æ•—ã—ã¾ã—ãŸï¼ˆPASSãŒå«ã¾ã‚Œã¦ã„ãªã„ï¼‰")
            pytest.fail(f"ãƒ†ã‚¹ãƒˆãŒå¤±æ•—ã—ã¾ã—ãŸ:\n{result_text}")
        
        SLog.log(LogCategory.TEST, LogEvent.COMPLETE, {"result": "PASS"}, "âœ… PASS: ãƒ†ã‚¹ãƒˆãŒæˆåŠŸã—ã¾ã—ãŸ")
        return result_text
