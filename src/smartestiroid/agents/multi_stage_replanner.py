"""
Multi-stage replanner for SmartestiRoid test framework.

This module provides a 3-stage replanning process for mini models.
"""

from typing import List, Dict, Any, Optional
from pydantic import BaseModel, Field
from colorama import Fore
from langchain_core.messages import HumanMessage
import allure

from ..models import Plan, Response, DecisionResult, ObjectiveStep, ObjectiveProgress
from ..config import RESULT_PASS, RESULT_FAIL


class ObjectiveEvaluation(BaseModel):
    """å€‹åˆ¥ã®ç›®æ¨™ã‚¹ãƒ†ãƒƒãƒ—ã®é”æˆè©•ä¾¡"""
    step_index: int = Field(description="ç›®æ¨™ã‚¹ãƒ†ãƒƒãƒ—ã®ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹")
    description: str = Field(description="ç›®æ¨™ã‚¹ãƒ†ãƒƒãƒ—ã®èª¬æ˜")
    achieved: bool = Field(description="é”æˆã•ã‚Œã¦ã„ã‚‹ã‹ã©ã†ã‹")
    evidence: str = Field(description="é”æˆ/æœªé”æˆã®æ ¹æ‹ ")


class StateAnalysis(BaseModel):
    """ãƒªãƒ—ãƒ©ãƒ³æ™‚ã®ç”»é¢çŠ¶æ…‹åˆ†æçµæœ"""
    screen_changes: str = Field(description="å‰ã‚¹ãƒ†ãƒƒãƒ—ã‹ã‚‰ã®ç”»é¢å¤‰åŒ–ã¨å·®åˆ†ï¼ˆUIè¦ç´ ã®è¿½åŠ /å‰Šé™¤/å¤‰æ›´ï¼‰")
    current_screen_type: str = Field(description="ç¾åœ¨ã®ç”»é¢ã®ç¨®é¡ï¼ˆä¾‹ï¼šãƒ›ãƒ¼ãƒ ç”»é¢ã€æ¤œç´¢çµæœã€è¨­å®šç”»é¢ãªã©ï¼‰")
    main_elements: str = Field(description="ç”»é¢ä¸Šã®ä¸»è¦UIè¦ç´ ã®èª¬æ˜")
    blocking_dialogs: Optional[str] = Field(default=None, description="ç›®æ¨™é”æˆã‚’å¦¨ã’ã‚‹ãƒ€ã‚¤ã‚¢ãƒ­ã‚°ã‚„ã‚ªãƒ¼ãƒãƒ¼ãƒ¬ã‚¤ãŒã‚ã‚‹å ´åˆã€ãã®å†…å®¹ã¨é–‰ã˜æ–¹")
    test_progress: str = Field(description="ãƒ†ã‚¹ãƒˆé€²æ—ã®è©•ä¾¡ï¼ˆå®šé‡çš„ã¾ãŸã¯å®šæ€§çš„ï¼‰")
    problems_detected: Optional[str] = Field(default=None, description="ç•°å¸¸æŒ™å‹•ãƒ»ã‚¨ãƒ©ãƒ¼ãƒ»äºˆæœŸã—ãªã„é·ç§»ãŒã‚ã‚‹å ´åˆã€ãã®è©³ç´°")
    
    # ç›®æ¨™ã‚¹ãƒ†ãƒƒãƒ—å˜ä½ã®è©•ä¾¡ï¼ˆæ–°è¦è¿½åŠ ï¼‰
    current_objective_achieved: bool = Field(description="ç¾åœ¨ã®ç›®æ¨™ã‚¹ãƒ†ãƒƒãƒ—ãŒé”æˆã•ã‚Œã¦ã„ã‚‹ã‹ã©ã†ã‹")
    current_objective_evidence: str = Field(description="ç¾åœ¨ã®ç›®æ¨™ã‚¹ãƒ†ãƒƒãƒ—ã®é”æˆ/æœªé”æˆã®æ ¹æ‹ ")
    
    # å¾“æ¥ã®ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ï¼ˆäº’æ›æ€§ç¶­æŒï¼‰
    goal_achieved: bool = Field(description="å…¨ä½“ã®ç›®æ¨™ãŒé”æˆã•ã‚Œã¦ã„ã‚‹ã‹ã©ã†ã‹")
    goal_achievement_reason: str = Field(description="ç›®æ¨™é”æˆ/æœªé”æˆã®åˆ¤æ–­æ ¹æ‹ ï¼ˆãƒ­ã‚±ãƒ¼ã‚¿ãƒ¼æƒ…å ±ã‚„ç”»é¢çŠ¶æ…‹ã«åŸºã¥ãï¼‰")
    suggested_next_action: Optional[str] = Field(default=None, description="æ¬¡ã«å®Ÿè¡Œã™ã¹ãã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã®ææ¡ˆï¼ˆä»»æ„ï¼‰")


class MultiStageReplanner:
    """3æ®µéšã«åˆ†ã‘ã¦replanã‚’å®Ÿè¡Œã™ã‚‹ã‚¯ãƒ©ã‚¹ï¼ˆminiãƒ¢ãƒ‡ãƒ«ç”¨ï¼‰"""
    
    def __init__(self, llm, knowhow: str, token_callback=None):
        self.llm = llm
        self.knowhow = knowhow
        self.model_name = llm.model_name if hasattr(llm, 'model_name') else "unknown"
        self.token_callback = token_callback  # track_query()ç”¨ã«ä¿æŒ
    
    async def analyze_state(
        self,
        goal: str,
        original_plan: list,
        past_steps: list,
        locator: str,
        previous_image_url: str = "",
        current_image_url: str = "",
        objective_progress: Optional[ObjectiveProgress] = None
    ) -> StateAnalysis:
        """ã‚¹ãƒ†ãƒ¼ã‚¸1: ç”»åƒï¼ˆå‰å›/ç¾åœ¨ï¼‰ã¨ãƒ­ã‚±ãƒ¼ã‚¿ãƒ¼ã‹ã‚‰ç¾çŠ¶ã‚’æŠŠæ¡

        ç”»åƒãŒã‚ã‚‹å ´åˆã¯LLMã¸ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«ã§æ¸¡ã—ã€å·®åˆ†è¨€åŠã‚’ä¿ƒã™ã€‚
        æ§‹é€ åŒ–ã•ã‚ŒãŸStateAnalysisã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã‚’è¿”ã™ã€‚
        
        Args:
            goal: å…¨ä½“ã®ç›®æ¨™
            original_plan: å…ƒã®å®Ÿè¡Œè¨ˆç”»
            past_steps: å®Œäº†æ¸ˆã¿ã‚¹ãƒ†ãƒƒãƒ—
            locator: ç”»é¢ã®ãƒ­ã‚±ãƒ¼ã‚¿ãƒ¼æƒ…å ±
            previous_image_url: å‰å›ã®ã‚¹ã‚¯ãƒªãƒ¼ãƒ³ã‚·ãƒ§ãƒƒãƒˆ
            current_image_url: ç¾åœ¨ã®ã‚¹ã‚¯ãƒªãƒ¼ãƒ³ã‚·ãƒ§ãƒƒãƒˆ
            objective_progress: ç›®æ¨™é€²æ—ç®¡ç†ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆï¼ˆæ–°è¦è¿½åŠ ï¼‰
        """
        # é€²æ—æƒ…å ±ã‚’è¨ˆç®—
        total_steps = len(original_plan)
        completed_steps = len(past_steps)
        remaining_steps = max(total_steps - completed_steps, 0)
        
        # ç›®æ¨™ã‚¹ãƒ†ãƒƒãƒ—æƒ…å ±ã‚’æ§‹ç¯‰
        objective_info = ""
        current_objective = ""
        if objective_progress:
            current_step = objective_progress.get_current_step()
            if current_step:
                current_objective = current_step.description
            
            # å…¨ç›®æ¨™ã‚¹ãƒ†ãƒƒãƒ—ã®ä¸€è¦§
            objective_list = []
            for step in objective_progress.objective_steps:
                status_icon = {
                    "completed": "âœ…",
                    "in_progress": "ğŸ”„",
                    "pending": "â³",
                    "failed": "âŒ",
                    "skipped": "â­ï¸"
                }.get(step.status, "?")
                type_label = "ğŸ¯" if step.step_type == "objective" else "ğŸ”§"
                objective_list.append(f"  {status_icon} {type_label} [{step.index}] {step.description}")
            
            objective_info = f"""
ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ç›®æ¨™ã‚¹ãƒ†ãƒƒãƒ—ã€‘ï¼ˆã“ã‚Œã‚‰ãŒé”æˆã•ã‚ŒãŸã‹ã‚’è©•ä¾¡ã™ã‚‹åŸºæº–ï¼‰
{chr(10).join(objective_list)}

ã€ç¾åœ¨è©•ä¾¡ä¸­ã®ç›®æ¨™ã‚¹ãƒ†ãƒƒãƒ—ã€‘
{current_objective}

ã€ç›®æ¨™é€²æ—ã€‘
{objective_progress.get_completed_objectives_count()}/{objective_progress.get_total_objectives_count()} ç›®æ¨™å®Œäº†
"""
        
        prompt_text = f"""
ã‚ãªãŸã¯ç”»é¢çŠ¶æ…‹ã‚’åˆ†æã™ã‚‹ã‚¨ã‚­ã‚¹ãƒ‘ãƒ¼ãƒˆã§ã™ã€‚

ã€å…¨ä½“ã®ç›®æ¨™ã€‘
{goal}
{objective_info}

ã€LLMå®Ÿè¡Œè¨ˆç”»ã®é€²æ—ã€‘ï¼ˆå‚è€ƒæƒ…å ±ï¼šç›®æ¨™é”æˆã®ãŸã‚ã«ç”Ÿæˆã•ã‚ŒãŸå®Ÿè¡Œæ‰‹é †ï¼‰
è¨ˆç”»ã‚¹ãƒ†ãƒƒãƒ—æ•°: {total_steps}
å®Œäº†ã‚¹ãƒ†ãƒƒãƒ—æ•°: {completed_steps}
æ®‹ã‚Šã‚¹ãƒ†ãƒƒãƒ—æ•°: {remaining_steps}
æœ€å¾Œã®å®Œäº†ã‚¹ãƒ†ãƒƒãƒ—: {past_steps[-1][0] if past_steps else "(ãªã—)"}

ã€é‡è¦ã€‘è©•ä¾¡åŸºæº–ã«ã¤ã„ã¦
- LLMå®Ÿè¡Œè¨ˆç”»ã®é€²æ—ã§ã¯ãªãã€ã€Œãƒ¦ãƒ¼ã‚¶ãƒ¼ç›®æ¨™ã‚¹ãƒ†ãƒƒãƒ—ã€ãŒé”æˆã•ã‚ŒãŸã‹ã§åˆ¤æ–­ã™ã‚‹ã“ã¨
- å®Ÿè¡Œè¨ˆç”»ãŒå…¨ã¦å®Œäº†ã—ã¦ã‚‚ã€ç›®æ¨™ã‚¹ãƒ†ãƒƒãƒ—ãŒæœªé”æˆãªã‚‰ã€Œæœªé”æˆã€ã¨åˆ¤æ–­ã™ã‚‹ã“ã¨
- ç¾åœ¨è©•ä¾¡ä¸­ã®ç›®æ¨™ã‚¹ãƒ†ãƒƒãƒ—ã€Œ{current_objective or goal}ã€ãŒé”æˆã•ã‚Œã¦ã„ã‚‹ã‹ã‚’ç‰¹ã«è©•ä¾¡ã™ã‚‹ã“ã¨

ã€åˆ†ææŒ‡ç¤ºã€‘
1. å‰ã‚¹ãƒ†ãƒƒãƒ—ã‹ã‚‰ã®ç”»é¢å¤‰åŒ–ã¨å·®åˆ†ï¼ˆUIè¦ç´ ã®è¿½åŠ /å‰Šé™¤/å¤‰æ›´ï¼‰
2. ç¾åœ¨ã®ç”»é¢ã®ç¨®é¡ï¼ˆä¾‹ï¼šãƒ›ãƒ¼ãƒ ç”»é¢ã€æ¤œç´¢çµæœã€è¨­å®šç”»é¢ãªã©ï¼‰
3. ç”»é¢ä¸Šã®ä¸»è¦UIè¦ç´ ã®èª¬æ˜
4. ç›®æ¨™é”æˆã‚’å¦¨ã’ã‚‹ãƒ€ã‚¤ã‚¢ãƒ­ã‚°ã‚„ã‚ªãƒ¼ãƒãƒ¼ãƒ¬ã‚¤ã®æœ‰ç„¡ï¼ˆé‡è¦ï¼šã“ã‚ŒãŒã‚ã‚Œã°ã¾ãšå‡¦ç†ãŒå¿…è¦ï¼‰
5. ç¾åœ¨ã®ç›®æ¨™ã‚¹ãƒ†ãƒƒãƒ—ãŒé”æˆã•ã‚Œã¦ã„ã‚‹ã‹ã©ã†ã‹
6. ç¾åœ¨ã®ç›®æ¨™ã‚¹ãƒ†ãƒƒãƒ—ã®é”æˆ/æœªé”æˆã®æ ¹æ‹ 
7. å…¨ä½“ã®ç›®æ¨™ãŒé”æˆã•ã‚Œã¦ã„ã‚‹ã‹ã©ã†ã‹
8. æ¬¡ã«å®Ÿè¡Œã™ã¹ãã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã®ææ¡ˆ

ç¾åœ¨ã®ãƒ­ã‚±ãƒ¼ã‚¿ãƒ¼æƒ…å ±:
{locator}

ç”»é¢ã‚¹ã‚¯ãƒªãƒ¼ãƒ³ã‚·ãƒ§ãƒƒãƒˆï¼ˆå‰å›ã®ç”»é¢ã¨ç¾åœ¨ã®ç”»é¢):
"""

        content_blocks: List[Dict[str, Any]] = [{"type": "text", "text": prompt_text}]
        if previous_image_url:
            content_blocks.append({"type": "image_url", "image_url": {"url": previous_image_url}})
        if current_image_url:
            content_blocks.append({"type": "image_url", "image_url": {"url": current_image_url}})

        # æ§‹é€ åŒ–å‡ºåŠ›ã‚’ä½¿ç”¨
        structured_llm = self.llm.with_structured_output(StateAnalysis)
        
        # track_query()ã§ã‚¯ã‚¨ãƒªã”ã¨ã®ãƒˆãƒ¼ã‚¯ãƒ³ä½¿ç”¨é‡ã‚’è¨˜éŒ²
        with self.token_callback.track_query():
            state_analysis: StateAnalysis = await structured_llm.ainvoke([HumanMessage(content=content_blocks)])
        
        print(Fore.MAGENTA + f"[MultiStageReplanner.analyze_state model: {self.model_name}] State analysis completed")
        print(Fore.CYAN + f"  - screen_type: {state_analysis.current_screen_type}")
        print(Fore.CYAN + f"  - current_objective_achieved: {state_analysis.current_objective_achieved}")
        print(Fore.CYAN + f"  - goal_achieved: {state_analysis.goal_achieved}")
        print(Fore.CYAN + f"  - blocking_dialogs: {state_analysis.blocking_dialogs or 'None'}")
        return state_analysis

    
    async def decide_action(
        self, 
        goal: str, 
        original_plan: list, 
        past_steps: list, 
        state_analysis: StateAnalysis,
        objective_progress: Optional[ObjectiveProgress] = None
    ) -> tuple:
        """ã‚¹ãƒ†ãƒ¼ã‚¸2: Plan/Responseã©ã¡ã‚‰ã‚’è¿”ã™ã¹ãã‹åˆ¤æ–­ï¼ˆæ§‹é€ åŒ–å‡ºåŠ›ï¼‰
        
        Args:
            goal: ãƒ†ã‚¹ãƒˆç›®æ¨™
            original_plan: å…ƒã®è¨ˆç”»
            past_steps: å®Œäº†æ¸ˆã¿ã‚¹ãƒ†ãƒƒãƒ—
            state_analysis: analyze_stateã‹ã‚‰ã®æ§‹é€ åŒ–ã•ã‚ŒãŸçŠ¶æ…‹åˆ†æçµæœ
            objective_progress: ç›®æ¨™é€²æ—ç®¡ç†ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆï¼ˆæ–°è¦è¿½åŠ ï¼‰
        """
        remaining_steps = max(len(original_plan) - len(past_steps), 0)

        # ç›®æ¨™ã‚¹ãƒ†ãƒƒãƒ—ã®é€²æ—æƒ…å ±ã‚’æ§‹ç¯‰
        objective_info = ""
        all_objectives_completed = False
        if objective_progress:
            all_objectives_completed = objective_progress.is_all_objectives_completed()
            completed_count = objective_progress.get_completed_objectives_count()
            total_count = objective_progress.get_total_objectives_count()
            
            objective_info = f"""
ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ç›®æ¨™ã‚¹ãƒ†ãƒƒãƒ—ã®é€²æ—ã€‘
å®Œäº†: {completed_count}/{total_count}
å…¨ç›®æ¨™é”æˆ: {"Yes" if all_objectives_completed else "No"}
ç¾åœ¨ã®ç›®æ¨™ã‚¹ãƒ†ãƒƒãƒ—é”æˆ: {"Yes" if state_analysis.current_objective_achieved else "No"}
"""

        # StateAnalysisã‹ã‚‰çŠ¶æ…‹è¦ç´„ã‚’æ§‹ç¯‰
        state_summary = f"""
ç”»é¢ã‚¿ã‚¤ãƒ—: {state_analysis.current_screen_type}
ç”»é¢å¤‰åŒ–: {state_analysis.screen_changes}
ä¸»è¦è¦ç´ : {state_analysis.main_elements}
ãƒ–ãƒ­ãƒƒã‚­ãƒ³ã‚°ãƒ€ã‚¤ã‚¢ãƒ­ã‚°: {state_analysis.blocking_dialogs or "ãªã—"}
ãƒ†ã‚¹ãƒˆé€²æ—: {state_analysis.test_progress}
æ¤œå‡ºã•ã‚ŒãŸå•é¡Œ: {state_analysis.problems_detected or "ãªã—"}
ç¾åœ¨ã®ç›®æ¨™ã‚¹ãƒ†ãƒƒãƒ—é”æˆ: {"Yes" if state_analysis.current_objective_achieved else "No"}
ç¾åœ¨ã®ç›®æ¨™ã‚¹ãƒ†ãƒƒãƒ—æ ¹æ‹ : {state_analysis.current_objective_evidence}
å…¨ä½“ã®ç›®æ¨™é”æˆ: {"Yes" if state_analysis.goal_achieved else "No"}
é”æˆåˆ¤æ–­ç†ç”±: {state_analysis.goal_achievement_reason}
"""

        prompt = f"""ã‚ãªãŸã¯æ¬¡ã®ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã‚’å³å¯†ã«åˆ¤æ–­ã™ã‚‹ã‚¨ã‚­ã‚¹ãƒ‘ãƒ¼ãƒˆã§ã™ã€‚

ã€ç›®æ¨™ã€‘
{goal}
{objective_info}

ã€çŠ¶æ…‹åˆ†æçµæœã€‘
{state_summary}

ã€LLMå®Ÿè¡Œè¨ˆç”»ã®é€²æ—ã€‘ï¼ˆå‚è€ƒï¼‰
è¨ˆç”»ã‚¹ãƒ†ãƒƒãƒ—ç·æ•°: {len(original_plan)} / å®Œäº†: {len(past_steps)} / æ®‹ã‚Š: {remaining_steps}

ã€åˆ¤æ–­åŸºæº–ï¼ˆå³æ ¼ï¼‰ã€‘
â˜…é‡è¦â˜… åˆ¤æ–­åŸºæº–ã¯ã€Œãƒ¦ãƒ¼ã‚¶ãƒ¼ç›®æ¨™ã‚¹ãƒ†ãƒƒãƒ—ã€ã®é”æˆåº¦ã§ã™ã€‚LLMå®Ÿè¡Œè¨ˆç”»ã®é€²æ—ã§ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚

1. ãƒ–ãƒ­ãƒƒã‚­ãƒ³ã‚°ãƒ€ã‚¤ã‚¢ãƒ­ã‚°ãŒã‚ã‚‹ â†’ decision=PLANï¼ˆã¾ãšéšœå®³ç‰©ã‚’å‡¦ç†ï¼‰
2. ç¾åœ¨ã®ç›®æ¨™ã‚¹ãƒ†ãƒƒãƒ—ãŒæœªé”æˆ â†’ decision=PLAN
3. ç¾åœ¨ã®ç›®æ¨™ã‚¹ãƒ†ãƒƒãƒ—ãŒé”æˆæ¸ˆã¿ã§ã€ã¾ã æ¬¡ã®ç›®æ¨™ã‚¹ãƒ†ãƒƒãƒ—ãŒã‚ã‚‹ â†’ decision=PLAN
4. å…¨ã¦ã®ç›®æ¨™ã‚¹ãƒ†ãƒƒãƒ—ãŒé”æˆæ¸ˆã¿ â†’ decision=RESPONSE

ã€å‡ºåŠ›ä»•æ§˜ã€‘
å³æ ¼ãªJSON
"""

        messages = [HumanMessage(content=prompt)]
        structured_llm = self.llm.with_structured_output(DecisionResult)
        try:
            if self.token_callback:
                with self.token_callback.track_query():
                    result = await structured_llm.ainvoke(messages)
            else:
                result = await structured_llm.ainvoke(messages)
            
            print(Fore.MAGENTA + f"[MultiStageReplanner.decide_action model: {self.model_name}] Decision: {result.decision}")
            decision_norm = result.decision.strip().upper()
            if decision_norm not in ("PLAN", "RESPONSE"):
                decision_norm = "PLAN"  # å®‰å…¨å´ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
            return decision_norm, result.reason.strip()
        except Exception as e:
            # æ§‹é€ åŒ–å‡ºåŠ›å¤±æ•—æ™‚ã¯å®‰å…¨å´ã§PLANã‚’è¿”ã™
            print(Fore.RED + f"Structured Output Error: {e}")
            allure.attach(str(e), name="âŒ decide_action: Structured Output Error", attachment_type=allure.attachment_type.TEXT)
            return "PLAN", "æ§‹é€ åŒ–å‡ºåŠ›ã‚¨ãƒ©ãƒ¼ã®ãŸã‚ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯"
    
    async def build_plan(self, goal: str, original_plan: list, past_steps: list, state_analysis: StateAnalysis) -> Plan:
        """ã‚¹ãƒ†ãƒ¼ã‚¸3a: æ¬¡ã®Planã‚’ä½œæˆ
        
        Args:
            goal: ãƒ†ã‚¹ãƒˆç›®æ¨™
            original_plan: å…ƒã®è¨ˆç”»
            past_steps: å®Œäº†æ¸ˆã¿ã‚¹ãƒ†ãƒƒãƒ—
            state_analysis: analyze_stateã‹ã‚‰ã®æ§‹é€ åŒ–ã•ã‚ŒãŸçŠ¶æ…‹åˆ†æçµæœ
        """
        remaining = original_plan[len(past_steps):]
        total_steps = len(original_plan)
        completed_steps = len(past_steps)
        remaining_count = len(remaining)
        
        # StateAnalysisã‹ã‚‰çŠ¶æ…‹è¦ç´„ã‚’æ§‹ç¯‰
        state_summary = f"""
ç”»é¢ã‚¿ã‚¤ãƒ—: {state_analysis.current_screen_type}
ç”»é¢å¤‰åŒ–: {state_analysis.screen_changes}
ä¸»è¦è¦ç´ : {state_analysis.main_elements}
ãƒ–ãƒ­ãƒƒã‚­ãƒ³ã‚°ãƒ€ã‚¤ã‚¢ãƒ­ã‚°: {state_analysis.blocking_dialogs or "ãªã—"}
ãƒ†ã‚¹ãƒˆé€²æ—: {state_analysis.test_progress}
æ¤œå‡ºã•ã‚ŒãŸå•é¡Œ: {state_analysis.problems_detected or "ãªã—"}
ç›®æ¨™é”æˆ: {"Yes" if state_analysis.goal_achieved else "No"}
é”æˆåˆ¤æ–­ç†ç”±: {state_analysis.goal_achievement_reason}
æ¬¡ã®ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ææ¡ˆ: {state_analysis.suggested_next_action or "ãªã—"}
"""
        
        prompt = f"""
ã‚ãªãŸã¯å®Ÿè¡Œè¨ˆç”»ã‚’ä½œæˆã™ã‚‹ã‚¨ã‚­ã‚¹ãƒ‘ãƒ¼ãƒˆã§ã™ã€‚

ç›®æ¨™
{goal}

ç¾åœ¨ã®çŠ¶æ…‹åˆ†æçµæœ:
{state_summary}

ã€é€²æ—çŠ¶æ³ã€‘
è¨ˆç”»ç·ã‚¹ãƒ†ãƒƒãƒ—æ•°: {total_steps}
å®Œäº†æ¸ˆã¿ã‚¹ãƒ†ãƒƒãƒ—æ•°: {completed_steps}
æ®‹ã‚Šã‚¹ãƒ†ãƒƒãƒ—æ•°: {remaining_count}
é€²æ—ç‡: {(completed_steps / total_steps * 100) if total_steps > 0 else 0:.0f}%

æ®‹ã‚Šã®å€™è£œã‚¹ãƒ†ãƒƒãƒ—:
{remaining}

ãƒã‚¦ãƒã‚¦:   
{self.knowhow}

ã‚¿ã‚¹ã‚¯:
ç›®æ¨™é”æˆã®ãŸã‚ã«å¿…è¦ãªæœ€é©ãªã‚¹ãƒ†ãƒƒãƒ—åˆ—ã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚ä»¥ä¸‹ã‚’å¿…ãšå®ˆã‚‹ã“ã¨ï¼š
- ãƒ–ãƒ­ãƒƒã‚­ãƒ³ã‚°ãƒ€ã‚¤ã‚¢ãƒ­ã‚°ãŒã‚ã‚‹å ´åˆã¯ã€ã¾ãšãã‚Œã‚’é–‰ã˜ã‚‹ã‚¹ãƒ†ãƒƒãƒ—ã‚’æœ€åˆã«å«ã‚ã‚‹ã“ã¨
- ã‚¹ãƒ†ãƒƒãƒ—ã‚’å®Ÿè¡Œã§ãã‚‹çŠ¶æ…‹ã§ãªã„å ´åˆã¯ã€ç¾åœ¨ã®çŠ¶æ…‹ã‚’è€ƒæ…®ã—ã¦æœ€é©ãªã‚¹ãƒ†ãƒƒãƒ—ã‚’å†æ§‹ç¯‰ã—ã¦ãã ã•ã„
- å¯èƒ½ãªã‚‰æ—¢å­˜æœªå®Œäº†ã‚¹ãƒ†ãƒƒãƒ—ã‚’å†åˆ©ç”¨ã—é‡è¤‡ã‚’é¿ã‘ã‚‹ã“ã¨
- ã‚¹ãƒ†ãƒƒãƒ—ã‚’é¸æŠã—ãŸæ ¹æ‹ ï¼ˆé€²æ—ãƒ»ç”»é¢è¦ç´ ãƒ»æ®‹ã‚Šç›®æ¨™ï¼‰ã‚’ç°¡æ½”ã«è¨€èªåŒ–ã™ã‚‹ã“ã¨
- ç¾åœ¨ã®çŠ¶æ…‹ã‚’è€ƒæ…®ã™ã‚‹ã“ã¨
- ä¸è¦ãªã‚¹ãƒ†ãƒƒãƒ—ã¯è¿½åŠ ã—ãªã„
- å„ã‚¹ãƒ†ãƒƒãƒ—ã¯å…·ä½“çš„ã§å®Ÿè¡Œå¯èƒ½ãªã“ã¨
- ç›®æ¨™ã®æ‰‹é †ã‚’è¸ã¾ãˆãŸã€ç›®æ¨™ã‚’é”æˆã™ã‚‹ãŸã‚ã®å…¨ã¦ã®ã‚¹ãƒ†ãƒƒãƒ—åˆ—ãŒãµãã¾ã‚Œã¦ã„ã‚‹ã“ã¨

ã€é‡è¦ã€‘ã‚¹ãƒ†ãƒƒãƒ—ã®åŠ¹ç‡åŒ–:
é–¢é€£ã™ã‚‹é€£ç¶šæ“ä½œã¯**1ã¤ã®ã‚¹ãƒ†ãƒƒãƒ—ã«ã¾ã¨ã‚ã‚‹ã“ã¨**ã€‚ä¸å¿…è¦ã«ç´°ã‹ãåˆ†å‰²ã—ãªã„ã“ã¨ã€‚

â—† å…¸å‹ãƒ‘ã‚¿ãƒ¼ãƒ³ï¼ˆã“ã‚Œã‚‰ã¯å¿…ãš1ã‚¹ãƒ†ãƒƒãƒ—ã«ã¾ã¨ã‚ã‚‹ï¼‰:
- ãƒ†ã‚­ã‚¹ãƒˆå…¥åŠ›ç³»: ã€Œæ¤œç´¢ãƒœãƒƒã‚¯ã‚¹ã‚’ã‚¿ãƒƒãƒ—ã—ã€'ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰'ã‚’å…¥åŠ›ã—ã¦æ¤œç´¢ãƒœã‚¿ãƒ³ã‚’æŠ¼ã™ã€
- ãƒŠãƒ“ã‚²ãƒ¼ã‚·ãƒ§ãƒ³ç³»: ã€Œè¨­å®šã‚¢ã‚¤ã‚³ãƒ³ã‚’ã‚¿ãƒƒãƒ—ã—ã€Wi-Fiè¨­å®šã‚’é–‹ã„ã¦ONã«åˆ‡ã‚Šæ›¿ãˆã‚‹ã€
- ç¢ºèªãƒ»æ¤œè¨¼ç³»: ã€Œãƒšãƒ¼ã‚¸ã‚’ã‚¹ã‚¯ãƒ­ãƒ¼ãƒ«ã—ã¦ç›®çš„ã®è¦ç´ ã‚’æ¢ã—ã€è¦‹ã¤ã‹ã£ãŸã‚‰ã‚¿ãƒƒãƒ—ã™ã‚‹ã€
- âœ— åˆ†å‰²ç¦æ­¢ä¾‹: 1.ãƒœãƒƒã‚¯ã‚¹ã‚¿ãƒƒãƒ— 2.å…¥åŠ› 3.ãƒœã‚¿ãƒ³æŠ¼ä¸‹

â—† åˆ†å‰²ã™ã¹ãã‚±ãƒ¼ã‚¹ï¼ˆåˆ¥ã‚¹ãƒ†ãƒƒãƒ—ã«ã™ã‚‹ï¼‰:
- ç”»é¢é·ç§»ã‚’ä¼´ã†å ´åˆï¼ˆãƒ­ã‚±ãƒ¼ã‚¿ãƒ¼ãŒå¤‰ã‚ã‚‹ï¼‰
- å¾…æ©ŸãŒå¿…è¦ãªå ´åˆï¼ˆãƒšãƒ¼ã‚¸èª­ã¿è¾¼ã¿ã€å‡¦ç†å®Œäº†å¾…ã¡ï¼‰
- çµæœã®æ¤œè¨¼ãŒå¿…è¦ãªå ´åˆï¼ˆæ“ä½œå¾Œã®ç¢ºèªï¼‰
- åˆ¥ã‚¢ãƒ—ãƒª/ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã«åˆ‡ã‚Šæ›¿ã‚ã‚‹å ´åˆ

å³æ ¼ãƒ«ãƒ¼ãƒ«:
- ã‚¢ã‚«ã‚¦ãƒ³ãƒˆä½œæˆã¯ç¦æ­¢
- è‡ªå‹•ãƒ­ã‚°ã‚¤ãƒ³ã¯ç¦æ­¢

å‡ºåŠ›å½¢å¼ï¼ˆJSONï¼‰:
å³å¯†ãªJSONå½¢å¼
"""
        
        messages = [HumanMessage(content=prompt)]
        structured_llm = self.llm.with_structured_output(Plan)
        
        if self.token_callback:
            with self.token_callback.track_query():
                plan = await structured_llm.ainvoke(messages)
        else:
            plan = await structured_llm.ainvoke(messages)
        
        print(Fore.MAGENTA + f"[MultiStageReplanner.build_plan model: {self.model_name}] Plan created with {len(plan.steps)} steps")
        return plan
    
    async def build_response(
        self, 
        goal: str, 
        past_steps: list, 
        state_analysis: StateAnalysis,
        objective_progress: Optional[ObjectiveProgress] = None
    ) -> Response:
        """ã‚¹ãƒ†ãƒ¼ã‚¸3b: å®Œäº†Responseã‚’ä½œæˆ
        
        Args:
            goal: ãƒ†ã‚¹ãƒˆç›®æ¨™
            past_steps: å®Œäº†æ¸ˆã¿ã‚¹ãƒ†ãƒƒãƒ—
            state_analysis: analyze_stateã‹ã‚‰ã®æ§‹é€ åŒ–ã•ã‚ŒãŸçŠ¶æ…‹åˆ†æçµæœ
            objective_progress: ç›®æ¨™é€²æ—ç®¡ç†ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆï¼ˆæ–°è¦è¿½åŠ ï¼‰
        """
        completed_count = len(past_steps)
        
        # å®Œäº†ã—ãŸã‚¹ãƒ†ãƒƒãƒ—ã®ä¸€è¦§ã‚’ä½œæˆ
        completed_steps_list = "\n".join(
            f"{i+1}. {step[0]}" for i, step in enumerate(past_steps)
        ) if past_steps else "(ãªã—)"
        
        # ç›®æ¨™ã‚¹ãƒ†ãƒƒãƒ—ã®é€²æ—æƒ…å ±
        objective_summary = ""
        if objective_progress:
            objective_list = []
            for step in objective_progress.objective_steps:
                status_icon = "âœ…" if step.status == "completed" else "âŒ" if step.status == "failed" else "â³"
                objective_list.append(f"  {status_icon} {step.description}")
            
            objective_summary = f"""
ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ç›®æ¨™ã‚¹ãƒ†ãƒƒãƒ—ã®é”æˆçŠ¶æ³ã€‘
{chr(10).join(objective_list)}

å®Œäº†: {objective_progress.get_completed_objectives_count()}/{objective_progress.get_total_objectives_count()}
"""
        
        # StateAnalysisã‹ã‚‰çŠ¶æ…‹è¦ç´„ã‚’æ§‹ç¯‰
        state_summary = f"""
ç”»é¢ã‚¿ã‚¤ãƒ—: {state_analysis.current_screen_type}
ç”»é¢å¤‰åŒ–: {state_analysis.screen_changes}
ä¸»è¦è¦ç´ : {state_analysis.main_elements}
ãƒ†ã‚¹ãƒˆé€²æ—: {state_analysis.test_progress}
ç¾åœ¨ã®ç›®æ¨™ã‚¹ãƒ†ãƒƒãƒ—é”æˆ: {"Yes" if state_analysis.current_objective_achieved else "No"}
å…¨ä½“ã®ç›®æ¨™é”æˆ: {"Yes" if state_analysis.goal_achieved else "No"}
é”æˆåˆ¤æ–­ç†ç”±: {state_analysis.goal_achievement_reason}
"""
        
        prompt = f"""ã‚ãªãŸã¯ã‚¿ã‚¹ã‚¯å®Œäº†å ±å‘Šã‚’ä½œæˆã™ã‚‹ã‚¨ã‚­ã‚¹ãƒ‘ãƒ¼ãƒˆã§ã™ã€‚

ã€ç›®æ¨™ã€‘
{goal}
{objective_summary}

ã€ç¾åœ¨ã®çŠ¶æ…‹åˆ†æçµæœã€‘
{state_summary}

ã€å®Œäº†æ¸ˆã¿å®Ÿè¡Œã‚¹ãƒ†ãƒƒãƒ—ä¸€è¦§ã€‘
{completed_steps_list}

ã€ã‚¿ã‚¹ã‚¯ã€‘
ã‚¿ã‚¹ã‚¯ã®å®Œäº†ã‚’å ±å‘Šã—ã¦ãã ã•ã„ã€‚ä»¥ä¸‹ã‚’å«ã‚ã‚‹ã“ã¨ï¼š
1. status: {RESULT_PASS} ã¾ãŸã¯ {RESULT_FAIL} ã®ã„ãšã‚Œã‹ã‚’è¨­å®š
   - å…¨ã¦ã®ç›®æ¨™ã‚¹ãƒ†ãƒƒãƒ—ãŒé”æˆã•ã‚Œã¦ã„ã‚‹å ´åˆã¯ RESULT_PASS
   - ç›®æ¨™ã‚¹ãƒ†ãƒƒãƒ—ãŒæœªé”æˆã®å ´åˆã¯ RESULT_FAIL
2. reason: å®Œäº†ç†ç”±ã®è©³ç´°ï¼ˆ100ã€œ600æ–‡å­—ç¨‹åº¦ï¼‰
   - å„ç›®æ¨™ã‚¹ãƒ†ãƒƒãƒ—ã®é”æˆçŠ¶æ³
   - é”æˆã®æ ¹æ‹ ï¼ˆãƒ­ã‚±ãƒ¼ã‚¿ãƒ¼æƒ…å ±ã‚„ç”»é¢çŠ¶æ…‹ï¼‰
   - æœªé”æˆãŒã‚ã‚‹å ´åˆã¯ãã®ç†ç”±

å‡ºåŠ›å½¢å¼:
å³æ ¼ãªJSONå½¢å¼ï¼ˆstatus ã¨ reason ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã‚’æŒã¤ï¼‰
"""
        
        messages = [HumanMessage(content=prompt)]
        structured_llm = self.llm.with_structured_output(Response)
        
        if self.token_callback:
            with self.token_callback.track_query():
                resp = await structured_llm.ainvoke(messages)
        else:
            resp = await structured_llm.ainvoke(messages)
        
        print(Fore.MAGENTA + f"[MultiStageReplanner.build_response model: {self.model_name}] Response created: {resp.status}")
        return resp
